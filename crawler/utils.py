"""
ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
- ì œëª© ë§¤í•‘ (ì¼ë³¸ì–´ â†’ í•œêµ­ì–´)
- ë¦¬ë²„ìŠ¤ ì‘í’ˆ íŒë³„
- ì¥ë¥´ ë²ˆì—­
"""

import json
import os
import time
from pathlib import Path
from typing import Optional


# í”„ë¡œì íŠ¸ ë£¨íŠ¸
project_root = Path(__file__).parent.parent


# ì¥ë¥´ ë²ˆì—­ ë”•ì…”ë„ˆë¦¬ (ì¼ë³¸ì–´ â†’ í•œêµ­ì–´)
GENRE_TRANSLATIONS = {
    # í”½ì½”ë§ˆ ì¥ë¥´
    'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼': 'íŒíƒ€ì§€',
    'æ‹æ„›': 'ì—°ì• ',
    'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': 'ì•¡ì…˜',
    'ãƒ‰ãƒ©ãƒ': 'ë“œë¼ë§ˆ',
    'ãƒ›ãƒ©ãƒ¼': 'í˜¸ëŸ¬',
    'ãƒŸã‚¹ãƒ†ãƒªãƒ¼': 'ë¯¸ìŠ¤í„°ë¦¬',
    'ã‚¹ãƒãƒ¼ãƒ„': 'ìŠ¤í¬ì¸ ',
    'ã‚°ãƒ«ãƒ¡': 'ìš”ë¦¬',
    'æ—¥å¸¸': 'ì¼ìƒ',
    'TL': 'TL',
    'BL': 'BL',
    'è£ç¤¾ä¼š': 'ë’·ì„¸ê³„',
    'ã‚¢ãƒ³ã‚°ãƒ©': 'ì–¸ë”ê·¸ë¼ìš´ë“œ',
    'ãƒ›ãƒ©ãƒ¼ãƒ»ãƒŸã‚¹ãƒ†ãƒªãƒ¼': 'í˜¸ëŸ¬/ë¯¸ìŠ¤í„°ë¦¬',
    'è£ç¤¾ä¼šãƒ»ã‚¢ãƒ³ã‚°ãƒ©': 'ë’·ì„¸ê³„/ì–¸ë”ê·¸ë¼ìš´ë“œ',

    # ì¼ë°˜ ì¥ë¥´
    'ã‚³ãƒ¡ãƒ‡ã‚£': 'ì½”ë¯¸ë””',
    'ã‚µã‚¹ãƒšãƒ³ã‚¹': 'ì„œìŠ¤íœìŠ¤',
    'SF': 'SF',
    'ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ': 'íœ´ë¨¼ë“œë¼ë§ˆ',
    'å­¦åœ’': 'í•™ì›',
    'æ‹æ„›ãƒ‰ãƒ©ãƒ': 'ì—°ì• ë“œë¼ë§ˆ',
    'ãƒãƒ¼ãƒˆãƒ•ãƒ«': 'í›ˆí›ˆ',
    'å¾©è®': 'ë³µìˆ˜',
    'ç•°ä¸–ç•Œ': 'ì´ì„¸ê³„',
    'è»¢ç”Ÿ': 'ì „ìƒ',
    'å†’é™º': 'ëª¨í—˜',
    'ãƒãƒˆãƒ«': 'ë°°í‹€',
    'æ ¼é—˜': 'ê²©íˆ¬',
    'æ­´å²': 'ì—­ì‚¬',
    'æ™‚ä»£åŠ‡': 'ì‹œëŒ€ê·¹',
    'æ¨ç†': 'ì¶”ë¦¬',
    'æ¢åµ': 'íƒì •',
    'ã‚µãƒã‚¤ãƒãƒ«': 'ì„œë°”ì´ë²Œ',
    'ã‚¾ãƒ³ãƒ“': 'ì¢€ë¹„',
    'åŒ»ç™‚': 'ì˜ë£Œ',
    'æ–™ç†': 'ìš”ë¦¬',
    'éŸ³æ¥½': 'ìŒì•…',
    'èŠ¸èƒ½': 'ì—°ì˜ˆ',
    'ãƒ“ã‚¸ãƒã‚¹': 'ë¹„ì¦ˆë‹ˆìŠ¤',
    'ãŠä»•äº‹': 'ì§ì—…',
    'å®¶æ—': 'ê°€ì¡±',
    'å‹æƒ…': 'ìš°ì •',
    'é’æ˜¥': 'ì²­ì¶˜',
    'æˆé•·': 'ì„±ì¥',
    'è·æ¥­': 'ì§ì—…',
    'æ—¥å¸¸ç³»': 'ì¼ìƒê³„',
    'ç™’ã—': 'íë§',
    'æ„Ÿå‹•': 'ê°ë™',
    'æ³£ã‘ã‚‹': 'ëˆˆë¬¼',
    'ã‚®ãƒ£ã‚°': 'ê°œê·¸',
    'ãƒ©ãƒ–ã‚³ãƒ¡': 'ëŸ¬ë¸Œì½”ë¯¸ë””',
}


# ì°¸ì¡° ë°ì´í„° ë¡œë“œ (ì§€ì—° ë¡œë”©)
_riverse_titles = None
_title_mappings = None


def load_riverse_titles() -> dict:
    """ë¦¬ë²„ìŠ¤ ì‘í’ˆ ëª©ë¡ ë¡œë“œ (ìºì‹±)"""
    global _riverse_titles

    if _riverse_titles is None:
        try:
            path = project_root / 'data' / 'riverse_titles.json'
            with open(path, 'r', encoding='utf-8') as f:
                _riverse_titles = json.load(f)
            print(f"âœ… ë¦¬ë²„ìŠ¤ ì‘í’ˆ {len(_riverse_titles)}ê°œ ë¡œë“œ")
        except FileNotFoundError:
            print(f"âš ï¸  riverse_titles.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©")
            _riverse_titles = {}
        except json.JSONDecodeError:
            print(f"âŒ riverse_titles.json íŒŒì‹± ì‹¤íŒ¨. ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©")
            _riverse_titles = {}

    return _riverse_titles


def load_title_mappings() -> dict:
    """í•œêµ­ì–´ ì œëª© ë§¤í•‘ ë¡œë“œ (ìºì‹±)"""
    global _title_mappings

    if _title_mappings is None:
        try:
            path = project_root / 'data' / 'title_mappings.json'
            with open(path, 'r', encoding='utf-8') as f:
                _title_mappings = json.load(f)
            print(f"âœ… í•œêµ­ì–´ ì œëª© {len(_title_mappings)}ê°œ ë¡œë“œ")
        except FileNotFoundError:
            print(f"âš ï¸  title_mappings.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©")
            _title_mappings = {}
        except json.JSONDecodeError:
            print(f"âŒ title_mappings.json íŒŒì‹± ì‹¤íŒ¨. ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©")
            _title_mappings = {}

    return _title_mappings


def get_korean_title(jp_title: str) -> str:
    """
    ì œëª© â†’ í•œêµ­ì–´ ì œëª© ë§¤í•‘ (ì¼ë³¸ì–´ + ì˜ì–´ ì§€ì›)

    Args:
        jp_title: ì¼ë³¸ì–´ ë˜ëŠ” ì˜ì–´ ì œëª©

    Returns:
        í•œêµ­ì–´ ì œëª© (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
    """
    if not jp_title:
        return ""

    riverse = load_riverse_titles()
    mappings = load_title_mappings()

    # 1ìˆœìœ„: ì •í™•í•œ ë§¤ì¹­ (ë¦¬ë²„ìŠ¤ ì‘í’ˆ)
    if jp_title in riverse:
        return riverse[jp_title]

    # 2ìˆœìœ„: ì •í™•í•œ ë§¤ì¹­ (ì¼ë°˜ ë§¤í•‘)
    if jp_title in mappings:
        return mappings[jp_title]

    # 3ìˆœìœ„: ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ë§¤ì¹­ (ì˜ì–´ ì œëª©ìš©)
    title_lower = jp_title.lower()
    for key, kr in riverse.items():
        if key.lower() == title_lower:
            return kr
    for key, kr in mappings.items():
        if key.lower() == title_lower:
            return kr

    # 4ìˆœìœ„: ëŒ€ê´„í˜¸ ì œê±° í›„ ë§¤ì¹­ (ã€ã€‘, [], ())
    cleaned = jp_title
    for bracket in ['ã€', 'ã€‘', '[', ']', '(', ')']:
        cleaned = cleaned.replace(bracket, '')

    if cleaned != jp_title:
        if cleaned in riverse:
            return riverse[cleaned]
        if cleaned in mappings:
            return mappings[cleaned]

    # 5ìˆœìœ„: ë¶€ë¶„ ë§¤ì¹­ (4ê¸€ì ì´ìƒ)
    if len(jp_title) >= 4:
        for jp, kr in riverse.items():
            if len(jp) >= 4 and jp in jp_title:
                return kr

        for jp, kr in mappings.items():
            if len(jp) >= 4 and jp in jp_title:
                return kr

    return ""


def is_riverse_title(jp_title: str) -> bool:
    """
    ë¦¬ë²„ìŠ¤ ì‘í’ˆ ì—¬ë¶€ íŒë³„

    Args:
        jp_title: ì¼ë³¸ì–´/ì˜ì–´ ì œëª©

    Returns:
        True: ë¦¬ë²„ìŠ¤ ì‘í’ˆ, False: ì¼ë°˜ ì‘í’ˆ
    """
    if not jp_title:
        return False

    riverse = load_riverse_titles()

    # ì •í™•í•œ ë§¤ì¹­
    if jp_title in riverse:
        return True

    # ëŒ€ê´„í˜¸ ì œê±° í›„ ë§¤ì¹­
    cleaned = jp_title
    for bracket in ['ã€', 'ã€‘', '[', ']', '(', ')']:
        cleaned = cleaned.replace(bracket, '')

    if cleaned in riverse:
        return True

    # ë¶€ë¶„ ë§¤ì¹­ (4ê¸€ì ì´ìƒ)
    if len(jp_title) >= 4:
        for jp in riverse.keys():
            if len(jp) >= 4 and jp in jp_title:
                return True

    # í•œêµ­ì–´ ì œëª© ì—­ì²´í¬ (ì˜ì–´ ì œëª© â†’ í•œêµ­ì–´ ë§¤í•‘ â†’ ë¦¬ë²„ìŠ¤ ëª©ë¡ í™•ì¸)
    kr_title = get_korean_title(jp_title)
    if kr_title:
        kr_base = kr_title.split('[')[0].split('(')[0].strip()
        riverse_kr = set()
        for kr in riverse.values():
            riverse_kr.add(kr)
            riverse_kr.add(kr.split('[')[0].split('(')[0].strip())
        if kr_title in riverse_kr or kr_base in riverse_kr:
            return True

    return False


def translate_genre(jp_genre: str) -> str:
    """
    ì¼ë³¸ì–´ ì¥ë¥´ â†’ í•œêµ­ì–´ ë²ˆì—­

    Args:
        jp_genre: ì¼ë³¸ì–´ ì¥ë¥´ (ì˜ˆ: "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼" ë˜ëŠ” "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ / ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")

    Returns:
        í•œêµ­ì–´ ì¥ë¥´ (ì—†ìœ¼ë©´ ì›ë¬¸ ê·¸ëŒ€ë¡œ)
    """
    if not jp_genre:
        return ""

    # ë³µí•© ì¥ë¥´ ì²˜ë¦¬ (ì˜ˆ: "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ / ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    if ' / ' in jp_genre or '/' in jp_genre:
        # "/" ë˜ëŠ” " / "ë¡œ ë¶„ë¦¬
        separator = ' / ' if ' / ' in jp_genre else '/'
        genres = jp_genre.split(separator)
        translated = []

        for genre in genres:
            genre = genre.strip()
            if genre in GENRE_TRANSLATIONS:
                translated.append(GENRE_TRANSLATIONS[genre])
            else:
                # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
                found = False
                for jp, kr in GENRE_TRANSLATIONS.items():
                    if jp in genre:
                        translated.append(kr)
                        found = True
                        break
                if not found:
                    translated.append(genre)  # ì›ë¬¸ ìœ ì§€

        return ' / '.join(translated)

    # ë‹¨ì¼ ì¥ë¥´
    jp_genre = jp_genre.strip()

    # ì •í™•í•œ ë§¤ì¹­
    if jp_genre in GENRE_TRANSLATIONS:
        return GENRE_TRANSLATIONS[jp_genre]

    # ë¶€ë¶„ ë§¤ì¹­
    for jp, kr in GENRE_TRANSLATIONS.items():
        if jp in jp_genre:
            return kr

    # ë§¤ì¹­ ì‹¤íŒ¨ - ì›ë¬¸ ê·¸ëŒ€ë¡œ
    return jp_genre


def _extract_json(text: str) -> dict:
    """ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ ì¶”ì¶œ (robust)"""
    text = text.strip()
    if text.startswith("```"):
        text = text.split("\n", 1)[1]
        text = text.rsplit("```", 1)[0].strip()
    start = text.find("{")
    if start == -1:
        return {}
    depth = 0
    for i in range(start, len(text)):
        if text[i] == '{':
            depth += 1
        elif text[i] == '}':
            depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {}


def fill_missing_title_kr():
    """
    í¬ë¡¤ë§ í›„ title_kr ëˆ„ë½ ì‘í’ˆ ìë™ ë²ˆì—­.
    1. DBì—ì„œ title_kr ë¹ˆ ê³ ìœ  ì œëª© ìˆ˜ì§‘
    2. ê¸°ì¡´ ë§¤í•‘ìœ¼ë¡œ ë³µêµ¬ ê°€ëŠ¥í•œ ê²ƒ ë¨¼ì € ì ìš©
    3. ë‚˜ë¨¸ì§€ëŠ” Claude APIë¡œ ë°°ì¹˜ ë²ˆì—­
    4. title_mappings.json + DB(works, rankings) ì—…ë°ì´íŠ¸
    """
    try:
        import anthropic
    except ImportError:
        print("âš ï¸  anthropic íŒ¨í‚¤ì§€ ì—†ìŒ â€” ìë™ ë²ˆì—­ ê±´ë„ˆëœ€")
        return

    from dotenv import load_dotenv
    load_dotenv(project_root / '.env')
    load_dotenv(project_root / 'dashboard-next' / '.env.local', override=True)

    api_key = os.environ.get('ANTHROPIC_API_KEY', '')
    db_url = os.environ.get('SUPABASE_DB_URL', '')
    if not api_key or not db_url:
        print("âš ï¸  APIí‚¤ ë˜ëŠ” DB URL ì—†ìŒ â€” ìë™ ë²ˆì—­ ê±´ë„ˆëœ€")
        return

    import psycopg2

    # 1. DBì—ì„œ title_kr ëˆ„ë½ ì œëª© ìˆ˜ì§‘
    conn = psycopg2.connect(db_url)
    cur = conn.cursor()
    cur.execute("""
        SELECT DISTINCT title FROM works
        WHERE (title_kr IS NULL OR title_kr = '')
        ORDER BY title
    """)
    missing = [row[0] for row in cur.fetchall()]
    conn.close()

    if not missing:
        print("âœ… title_kr ëˆ„ë½ ì—†ìŒ")
        return

    print(f"\nğŸ”¤ title_kr ëˆ„ë½: {len(missing)}ê°œ")

    # 2. ê¸°ì¡´ ë§¤í•‘ìœ¼ë¡œ ë³µêµ¬
    mappings = load_title_mappings()
    already_mapped = {}
    still_missing = []
    for t in missing:
        kr = get_korean_title(t)
        if kr:
            already_mapped[t] = kr
        else:
            still_missing.append(t)

    if already_mapped:
        print(f"  ğŸ”„ ê¸°ì¡´ ë§¤í•‘ ë³µêµ¬: {len(already_mapped)}ê°œ")
        conn = psycopg2.connect(db_url)
        cur = conn.cursor()
        for jp, kr in already_mapped.items():
            cur.execute("UPDATE works SET title_kr=%s WHERE title=%s AND (title_kr IS NULL OR title_kr='')", (kr, jp))
            cur.execute("UPDATE rankings SET title_kr=%s WHERE title=%s AND (title_kr IS NULL OR title_kr='')", (kr, jp))
        conn.commit()
        conn.close()

    if not still_missing:
        print("âœ… ëª¨ë“  title_kr ë³µêµ¬ ì™„ë£Œ")
        return

    print(f"  ğŸ¤– ë²ˆì—­ í•„ìš”: {len(still_missing)}ê°œ")

    # 3. Claude API ë°°ì¹˜ ë²ˆì—­ (ë§¤ ë°°ì¹˜ í›„ ì¦‰ì‹œ ì €ì¥)
    client = anthropic.Anthropic(api_key=api_key)
    BATCH = 80
    total_translated = 0
    mappings_path = project_root / 'data' / 'title_mappings.json'

    for i in range(0, len(still_missing), BATCH):
        batch = still_missing[i:i+BATCH]
        titles_text = "\n".join(f"{j+1}. {t}" for j, t in enumerate(batch))
        result = {}

        for retry in range(3):
            try:
                resp = client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=8192,
                    messages=[{"role": "user", "content": f"""ë‹¤ìŒ ì¼ë³¸ì–´ ë§Œí™”/ì›¹íˆ° ì œëª©ë“¤ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.

ê·œì¹™:
- í•œêµ­ ì›¹íˆ°ì´ ì¼ë³¸ì–´ë¡œ ë²ˆì—­ëœ ê²ƒì´ë©´ ì›ë˜ í•œêµ­ì–´ ì œëª©ì„ ì°¾ì•„ì„œ ì ì–´ì£¼ì„¸ìš”
- ì¼ë³¸ ì›ì‘ì´ë©´ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”
- ì˜ì–´ ì œëª©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ë„ ë©ë‹ˆë‹¤
- ê³ ìœ ëª…ì‚¬(ìºë¦­í„°ëª… ë“±)ëŠ” ìŒì—­í•˜ì„¸ìš”
- ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”: {{"ì›ë³¸ì œëª©": "í•œêµ­ì–´ì œëª©", ...}}
- ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”

ì œëª© ëª©ë¡:
{titles_text}"""}]
                )
                result = _extract_json(resp.content[0].text)
                if result:
                    break
            except Exception as e:
                if 'credit balance' in str(e).lower() or '400' in str(e):
                    print(f"  âŒ API í¬ë ˆë”§ ë¶€ì¡± â€” ì¤‘ë‹¨")
                    break
                print(f"  âš ï¸  ë°°ì¹˜ {i//BATCH+1} ì˜¤ë¥˜ (ì¬ì‹œë„ {retry+1}/3): {e}")
                time.sleep(3)
        else:
            if not result:
                continue

        if not result:
            break  # credit exhaustion

        # ì¦‰ì‹œ DB ì €ì¥
        conn = psycopg2.connect(db_url)
        cur = conn.cursor()
        w_count = r_count = 0
        for jp, kr in result.items():
            if not kr:
                continue
            cur.execute("UPDATE works SET title_kr=%s WHERE title=%s AND (title_kr IS NULL OR title_kr='')", (kr, jp))
            w_count += cur.rowcount
            cur.execute("UPDATE rankings SET title_kr=%s WHERE title=%s AND (title_kr IS NULL OR title_kr='')", (kr, jp))
            r_count += cur.rowcount
        conn.commit()
        conn.close()

        # ì¦‰ì‹œ ë§¤í•‘ JSON ì €ì¥
        with open(mappings_path, 'r', encoding='utf-8') as f:
            current_mappings = json.load(f)
        added = 0
        for jp, kr in result.items():
            if kr and jp not in current_mappings:
                current_mappings[jp] = kr
                added += 1
        sorted_m = dict(sorted(current_mappings.items()))
        with open(mappings_path, 'w', encoding='utf-8') as f:
            json.dump(sorted_m, f, ensure_ascii=False, indent=2)

        total_translated += len(result)
        print(f"  âœ… ë°°ì¹˜ {i//BATCH+1}: {len(result)}ê°œ ë²ˆì—­ / DB: w{w_count} r{r_count} / ë§¤í•‘: +{added}")

        if i + BATCH < len(still_missing):
            time.sleep(1)

    # ë§¤í•‘ ìºì‹œ ë¬´íš¨í™”
    global _title_mappings
    _title_mappings = None

    print(f"  ğŸ“Š ì´ {total_translated}ê°œ ë²ˆì—­ ì™„ë£Œ")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("=" * 60)
    print("ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # ì¥ë¥´ ë²ˆì—­ í…ŒìŠ¤íŠ¸
    print("\n[ì¥ë¥´ ë²ˆì—­ í…ŒìŠ¤íŠ¸]")
    test_genres = [
        'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼',
        'æ‹æ„›',
        'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ / ã‚¢ã‚¯ã‚·ãƒ§ãƒ³',
        'ãƒ›ãƒ©ãƒ¼ãƒ»ãƒŸã‚¹ãƒ†ãƒªãƒ¼',
        'ì•Œ ìˆ˜ ì—†ëŠ” ì¥ë¥´'
    ]
    for genre in test_genres:
        print(f"  {genre} â†’ {translate_genre(genre)}")

    # ë¦¬ë²„ìŠ¤ íŒë³„ í…ŒìŠ¤íŠ¸
    print("\n[ë¦¬ë²„ìŠ¤ ì‘í’ˆ íŒë³„ í…ŒìŠ¤íŠ¸]")
    riverse = load_riverse_titles()
    if riverse:
        sample_titles = list(riverse.keys())[:3]
        for title in sample_titles:
            kr = get_korean_title(title)
            is_rv = is_riverse_title(title)
            print(f"  {title}")
            print(f"    â†’ í•œêµ­ì–´: {kr}")
            print(f"    â†’ ë¦¬ë²„ìŠ¤: {is_rv}")
    else:
        print("  âš ï¸  ë¦¬ë²„ìŠ¤ ì‘í’ˆ ë°ì´í„° ì—†ìŒ")

    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 60)
