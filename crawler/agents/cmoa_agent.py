"""
ì½”ë¯¹ì‹œëª¨ì•„ (ã‚³ãƒŸãƒƒã‚¯ã‚·ãƒ¼ãƒ¢ã‚¢) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- CSR + TLS ì´ìŠˆ (Playwright í•„ìˆ˜, ignore_https_errors)
- ë‹¨ì¼ í˜ì´ì§€ì— 200ê°œ í‘œì‹œ, ìƒìœ„ 50ê°œ ì‚¬ìš©
- IP ì œí•œ ì—†ìŒ
- ì…€ë ‰í„°: li.search_result_box (2026ë…„ í˜„ì¬ êµ¬ì¡°)
- ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹: /search/purpose/ranking/{slug}/ ê²½ë¡œë¡œ êµ¬ë¶„
"""

import re
from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class CmoaAgent(CrawlerAgent):
    """ì½”ë¯¹ì‹œëª¨ì•„ ì¢…í•© + ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    # ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ ë§¤í•‘ (URL: /ranking/{slug}/)
    GENRE_RANKINGS = {
        '': {'name': 'ì¢…í•©', 'slug': 'all'},
        'å°‘å¹´ãƒãƒ³ã‚¬': {'name': 'ì†Œë…„ë§Œí™”', 'slug': 'boy'},
        'é’å¹´ãƒãƒ³ã‚¬': {'name': 'ì²­ë…„ë§Œí™”', 'slug': 'gentle'},
        'å°‘å¥³ãƒãƒ³ã‚¬': {'name': 'ì†Œë…€ë§Œí™”', 'slug': 'girl'},
        'å¥³æ€§ãƒãƒ³ã‚¬': {'name': 'ì—¬ì„±ë§Œí™”', 'slug': 'lady'},
        'BL': {'name': 'BL', 'slug': 'boyslove'},
        'TL': {'name': 'TL', 'slug': 'teenslove'},
        'sexy': {'name': 'ì–´ëœíŠ¸', 'slug': 'sexy'},
    }

    def __init__(self):
        super().__init__(
            platform_id='cmoa',
            platform_name='ì½”ë¯¹ì‹œëª¨ì•„ (ì¢…í•©)',
            url='https://www.cmoa.jp/search/purpose/ranking/all/'
        )
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """
        ì½”ë¯¹ì‹œëª¨ì•„ ì¢…í•© + ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ í¬ë¡¤ë§

        DOM êµ¬ì¡°:
        <li class="search_result_box">
          <div class="search_result_box_left">
            <a href="/title/{id}/" class="title">
              <img class="volume_img" alt="ì œëª©" src="...">
            </a>
          </div>
          <div class="search_result_box_right">
            <div class="rank_area">
              <p class="title_rank r1">1ä½</p>
            </div>
            <div class="search_result_box_right_sec1">
              <a href="/title/{id}/" class="title">ì œëª©</a>
            </div>
            <div class="search_result_box_right_sec2">
              <p>ã‚¸ãƒ£ãƒ³ãƒ«ï¼š<a href="/search/genre/2/">å¥³æ€§ãƒãƒ³ã‚¬</a></p>
            </div>
          </div>
        </li>
        """
        context = await browser.new_context(ignore_https_errors=True)
        page = await context.new_page()
        all_rankings = []

        try:
            for genre_key, genre_info in self.GENRE_RANKINGS.items():
                label = genre_info['name']
                slug = genre_info['slug']
                url = f'https://www.cmoa.jp/search/purpose/ranking/{slug}/'

                self.logger.info(f"ğŸ“± ì½”ë¯¹ì‹œëª¨ì•„ [{label}] í¬ë¡¤ë§ ì¤‘... â†’ {url}")

                await page.goto(url, wait_until='domcontentloaded', timeout=20000)
                await page.wait_for_selector('li.search_result_box', timeout=10000)
                await page.wait_for_timeout(1000)

                items = await page.query_selector_all('li.search_result_box')
                self.logger.info(f"   ì‘í’ˆ ìš”ì†Œ {len(items)}ê°œ ë°œê²¬")

                rankings = []
                for item in items[:100]:
                    try:
                        entry = await self._parse_item(item)
                        if entry:
                            if genre_key and not entry['genre']:
                                entry['genre'] = genre_key
                            rankings.append(entry)
                    except Exception as e:
                        self.logger.debug(f"ì‘í’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                        continue

                rankings.sort(key=lambda x: x['rank'])
                self.genre_results[genre_key] = rankings
                self.logger.info(f"   âœ… [{label}]: {len(rankings)}ê°œ ì‘í’ˆ")

                if genre_key == '':
                    all_rankings = rankings

            return all_rankings

        finally:
            await page.close()
            await context.close()

    async def _parse_item(self, item) -> Dict[str, Any]:
        """ê°œë³„ ë­í‚¹ ì•„ì´í…œ íŒŒì‹±"""

        # 1. ìˆœìœ„: .title_rank í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ
        rank_el = await item.query_selector('.title_rank')
        if not rank_el:
            return None
        rank_text = (await rank_el.inner_text()).strip()
        match = re.search(r'(\d+)ä½', rank_text)
        if not match:
            return None
        rank = int(match.group(1))

        # 2. ì œëª©: .search_result_box_right_sec1 a.title
        title = None
        title_el = await item.query_selector('.search_result_box_right_sec1 a.title')
        if title_el:
            title = (await title_el.inner_text()).strip()

        # fallback: img alt
        if not title:
            img_el = await item.query_selector('img.volume_img')
            if img_el:
                title = await img_el.get_attribute('alt')

        if not title:
            return None

        # 3. URL: a.title href
        url = ''
        if title_el:
            href = await title_el.get_attribute('href')
            if href:
                url = f"https://www.cmoa.jp{href}" if not href.startswith('http') else href

        # 4. ì¥ë¥´: "ã‚¸ãƒ£ãƒ³ãƒ«ï¼š" ë‹¤ìŒì˜ <a> íƒœê·¸
        genre = ''
        sec2 = await item.query_selector('.search_result_box_right_sec2')
        if sec2:
            sec2_html = await sec2.inner_html()
            genre_match = re.search(r'ã‚¸ãƒ£ãƒ³ãƒ«ï¼š\s*<a[^>]*>([^<]+)</a>', sec2_html)
            if genre_match:
                genre = genre_match.group(1).strip()

        # 5. ì¸ë„¤ì¼: data-src (lazy loading) â†’ src fallback
        thumbnail_url = ''
        thumb_el = await item.query_selector('img.volume_img')
        if thumb_el:
            # data-srcì— ì‹¤ì œ URLì´ ìˆìŒ (lazy loading)
            thumb_src = await thumb_el.get_attribute('data-src') or ''
            if not thumb_src:
                thumb_src = await thumb_el.get_attribute('src') or ''
            if thumb_src and 'loader.png' not in thumb_src:
                thumbnail_url = f"https:{thumb_src}" if thumb_src.startswith('//') else thumb_src

        return {
            'rank': rank,
            'title': title.strip(),
            'genre': genre,
            'url': url,
            'thumbnail_url': thumbnail_url,
        }

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ì¢…í•© + ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ ëª¨ë‘ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        # ì¢…í•© ë­í‚¹ ì €ì¥
        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
            for item in data if item.get('thumbnail_url')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta, date=date, sub_category='')
        backup_to_json(date, self.platform_id, data)

        # ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ ì €ì¥
        for genre_key, rankings in self.genre_results.items():
            if genre_key == '':
                continue
            genre_name = self.GENRE_RANKINGS[genre_key]['name']
            save_rankings(date, self.platform_id, rankings, sub_category=genre_key)
            genre_meta = [
                {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
                 'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
                for item in rankings if item.get('thumbnail_url')
            ]
            if genre_meta:
                save_works_metadata(self.platform_id, genre_meta, date=date, sub_category=genre_key)
            self.logger.info(f"   ğŸ’¾ [{genre_name}]: {len(rankings)}ê°œ ì €ì¥")


if __name__ == "__main__":
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("ì½”ë¯¹ì‹œëª¨ì•„ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)

            try:
                agent = CmoaAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~5ìœ„):")
                    for item in result.data[:5]:
                        print(f"  {item['rank']}ìœ„: {item['title'][:40]}")
                        print(f"    ì¥ë¥´: {item['genre']}")
                        print(f"    URL: {item['url']}")

                    print(f"\nì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼:")
                    for gkey, rankings in agent.genre_results.items():
                        label = agent.GENRE_RANKINGS[gkey]['name']
                        print(f"  [{label}]: {len(rankings)}ê°œ")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
