"""
ì½”ë¯¹ì‹œëª¨ì•„ (ã‚³ãƒŸãƒƒã‚¯ã‚·ãƒ¼ãƒ¢ã‚¢) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- CSR + TLS ì´ìŠˆ (fetch ì‹œ ì—ëŸ¬, Playwright í•„ìˆ˜)
- ë‹¨ì¼ í˜ì´ì§€ (50ê°œ ì‘í’ˆ)
- IP ì œí•œ ì—†ìŒ

ê°œì„ ì‚¬í•­:
- selector ì •í™•ì„± í–¥ìƒ (fallback selector ì¶”ê°€)
- wait_until='domcontentloaded' (timeout ë¬¸ì œ í•´ê²°)
- ì—ì´ì „íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜
"""

from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent
from crawler.utils import get_korean_title, is_riverse_title, translate_genre


class CmoaAgent(CrawlerAgent):
    """ì½”ë¯¹ì‹œëª¨ì•„ ì¢…í•© ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    def __init__(self):
        super().__init__(
            platform_id='cmoa',
            platform_name='ì½”ë¯¹ì‹œëª¨ì•„ (ì¢…í•©)',
            url='https://www.cmoa.jp/search/purpose/ranking/all/'
        )

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """
        ì½”ë¯¹ì‹œëª¨ì•„ ì¢…í•© ë­í‚¹ 50ìœ„ í¬ë¡¤ë§

        Args:
            browser: Playwright ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤

        Returns:
            [{'rank': 1, 'title': 'ì œëª©', 'genre': 'ì¥ë¥´', 'url': 'http://...'}, ...]
        """
        # TLS ì—ëŸ¬ ìš°íšŒë¥¼ ìœ„í•´ ignore_https_errors ì„¤ì •
        context = await browser.new_context(ignore_https_errors=True)
        page = await context.new_page()
        rankings = []

        try:
            self.logger.info(f"ğŸ“± {self.platform_name} í¬ë¡¤ë§ ì¤‘...")
            self.logger.info(f"   URL: {self.url}")

            # ìˆ˜ì •: wait_until='domcontentloaded' (networkidle ëŒ€ì‹ )
            await page.goto(self.url, wait_until='domcontentloaded', timeout=20000)

            # JavaScript ë Œë”ë§ ëŒ€ê¸°
            # ìˆ˜ì •: ì—¬ëŸ¬ selector ì‹œë„ (ì‹¤ì œ DOMì— ë§ê²Œ)
            selectors_to_try = [
                'li.search_result_box',  # ê°€ì¥ ê°€ëŠ¥ì„± ë†’ìŒ
                '.product-item',
                '.ranking-item',
                'div.item',
                '.work-item',
                'article'
            ]

            items = None
            matched_selector = None

            for selector in selectors_to_try:
                try:
                    await page.wait_for_selector(selector, timeout=8000)
                    test_items = await page.query_selector_all(selector)

                    if test_items and len(test_items) > 0:
                        items = test_items
                        matched_selector = selector
                        self.logger.debug(f"Selector '{selector}' ë§¤ì¹­: {len(items)}ê°œ ìš”ì†Œ")
                        break
                except Exception:
                    continue

            if not items:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ëª¨ë“  selector ê²°í•©
                combined_selector = ', '.join(selectors_to_try)
                items = await page.query_selector_all(combined_selector)
                matched_selector = "combined"

            self.logger.info(f"   ì‘í’ˆ ìš”ì†Œ {len(items)}ê°œ ë°œê²¬ (selector: {matched_selector})")

            for i, item in enumerate(items[:50], 1):  # ìƒìœ„ 50ê°œë§Œ
                try:
                    # ìˆœìœ„ëŠ” ìˆœì„œëŒ€ë¡œ ë‚˜ì—´ë¨
                    rank = i

                    # ì œëª© ì¶”ì¶œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
                    title = await self._extract_title(item)

                    if not title:
                        self.logger.debug(f"{i}ë²ˆì§¸ ì‘í’ˆ: ì œëª© ì¶”ì¶œ ì‹¤íŒ¨, ìŠ¤í‚µ")
                        continue

                    # URL ì¶”ì¶œ
                    url_full = await self._extract_url(item)

                    # ì¥ë¥´ ì¶”ì¶œ
                    genre = await self._extract_genre(item)

                    # í•œêµ­ì–´ ì œëª© ë° ë¦¬ë²„ìŠ¤ ì—¬ë¶€ í™•ì¸
                    title_kr = get_korean_title(title)
                    is_riverse = is_riverse_title(title)
                    genre_kr = translate_genre(genre)

                    rankings.append({
                        'rank': rank,
                        'title': title.strip(),
                        'title_kr': title_kr,
                        'genre': genre.strip() if genre else "",
                        'genre_kr': genre_kr,
                        'url': url_full,
                        'is_riverse': is_riverse
                    })

                except Exception as e:
                    self.logger.debug(f"{i}ë²ˆì§¸ ì‘í’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

            self.logger.info(f"   âœ… {self.platform_name}: {len(rankings)}ê°œ ì‘í’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            return rankings

        finally:
            await page.close()
            await context.close()

    async def _extract_title(self, item) -> str:
        """
        ì œëª© ì¶”ì¶œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)

        ìš°ì„ ìˆœìœ„:
        1. .title, .work-title selector
        2. h3, h2 íƒœê·¸
        3. ë§í¬ì˜ aria-label
        4. ë§í¬ í…ìŠ¤íŠ¸
        5. ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì‹±
        """
        # Method 1: title class
        for selector in ['.title', '.work-title', '.product-title']:
            title_elem = await item.query_selector(selector)
            if title_elem:
                title = await title_elem.inner_text()
                if title and len(title.strip()) > 0:
                    return title.strip()

        # Method 2: heading tags
        for selector in ['h3', 'h2', 'h4']:
            title_elem = await item.query_selector(selector)
            if title_elem:
                title = await title_elem.inner_text()
                if title and len(title.strip()) > 0:
                    return title.strip()

        # Method 3: link aria-label
        link_elem = await item.query_selector('a')
        if link_elem:
            aria_label = await link_elem.get_attribute('aria-label')
            if aria_label and len(aria_label.strip()) > 0:
                return aria_label.strip()

            # Method 4: link text
            link_text = await link_elem.inner_text()
            if link_text:
                # ì²« ë²ˆì§¸ ì¤„ì„ ì œëª©ìœ¼ë¡œ ê°„ì£¼
                lines = link_text.split('\n')
                for line in lines:
                    line = line.strip()
                    if len(line) > 2:
                        return line

        # Method 5: ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì‹±
        text = await item.inner_text()
        if text:
            lines = text.split('\n')
            for line in lines:
                line = line.strip()
                if len(line) > 2:  # ìµœì†Œ 3ê¸€ì ì´ìƒ
                    return line

        return ""

    async def _extract_url(self, item) -> str:
        """URL ì¶”ì¶œ"""
        link_elem = await item.query_selector('a')
        if not link_elem:
            return ""

        url_path = await link_elem.get_attribute('href')
        if not url_path:
            return ""

        if url_path.startswith('http'):
            return url_path
        else:
            return f"https://www.cmoa.jp{url_path}"

    async def _extract_genre(self, item) -> str:
        """
        ì¥ë¥´ ì¶”ì¶œ

        ìš°ì„ ìˆœìœ„:
        1. .genre, .category selector
        2. í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
        """
        # Method 1: selector
        for selector in ['.genre', '.category', '.tag']:
            genre_elem = await item.query_selector(selector)
            if genre_elem:
                genre = await genre_elem.inner_text()
                if genre:
                    return genre.strip()

        # Method 2: í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
        text = await item.inner_text()
        return self._extract_genre_from_text(text)

    def _extract_genre_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì¥ë¥´ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        genres = [
            'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼', 'æ‹æ„›', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³', 'ãƒ‰ãƒ©ãƒ', 'ãƒ›ãƒ©ãƒ¼', 'ãƒŸã‚¹ãƒ†ãƒªãƒ¼',
            'ã‚³ãƒ¡ãƒ‡ã‚£', 'ã‚µã‚¹ãƒšãƒ³ã‚¹', 'SF', 'å­¦åœ’', 'ã‚¹ãƒãƒ¼ãƒ„', 'ã‚°ãƒ«ãƒ¡',
            'æ—¥å¸¸', 'BL', 'TL', 'ç•°ä¸–ç•Œ', 'è»¢ç”Ÿ', 'å¾©è®', 'ãƒãƒˆãƒ«', 'æ­´å²'
        ]

        for genre in genres:
            if genre in text:
                return genre

        return ""


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("ì½”ë¯¹ì‹œëª¨ì•„ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=False)  # ë””ë²„ê¹…ìš©

            try:
                agent = CmoaAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~3ìœ„):")
                    for item in result.data[:3]:
                        print(f"  {item['rank']}ìœ„: {item['title']}")
                        if item['title_kr']:
                            print(f"    í•œêµ­ì–´: {item['title_kr']}")
                        print(f"    ì¥ë¥´: {item['genre']} ({item['genre_kr']})")
                        print(f"    ë¦¬ë²„ìŠ¤: {item['is_riverse']}")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
