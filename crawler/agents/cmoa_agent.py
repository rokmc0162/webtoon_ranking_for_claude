"""
ì½”ë¯¹ì‹œëª¨ì•„ (ã‚³ãƒŸãƒƒã‚¯ã‚·ãƒ¼ãƒ¢ã‚¢) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- CSR + TLS ì´ìŠˆ (Playwright í•„ìˆ˜, ignore_https_errors)
- ë‹¨ì¼ í˜ì´ì§€ì— 200ê°œ í‘œì‹œ, ìƒìœ„ 50ê°œ ì‚¬ìš©
- IP ì œí•œ ì—†ìŒ
- ì…€ë ‰í„°: li.search_result_box (2026ë…„ í˜„ì¬ êµ¬ì¡°)
"""

import re
from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class CmoaAgent(CrawlerAgent):
    """ì½”ë¯¹ì‹œëª¨ì•„ ì¢…í•© ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    def __init__(self):
        super().__init__(
            platform_id='cmoa',
            platform_name='ì½”ë¯¹ì‹œëª¨ì•„ (ì¢…í•©)',
            url='https://www.cmoa.jp/search/purpose/ranking/all/'
        )

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """
        ì½”ë¯¹ì‹œëª¨ì•„ ì¢…í•© ë­í‚¹ 50ìœ„ í¬ë¡¤ë§

        DOM êµ¬ì¡°:
        <li class="search_result_box">
          <div class="search_result_box_left">
            <a href="/title/{id}/" class="title">
              <img class="volume_img" alt="ì œëª©" src="...">
            </a>
          </div>
          <div class="search_result_box_right">
            <div class="rank_area">
              <p class="title_rank r1">1ä½</p>
            </div>
            <div class="search_result_box_right_sec1">
              <a href="/title/{id}/" class="title">ì œëª©</a>
            </div>
            <div class="search_result_box_right_sec2">
              <p>ã‚¸ãƒ£ãƒ³ãƒ«ï¼š<a href="/search/genre/2/">å¥³æ€§ãƒãƒ³ã‚¬</a></p>
            </div>
          </div>
        </li>
        """
        context = await browser.new_context(ignore_https_errors=True)
        page = await context.new_page()
        rankings = []

        try:
            self.logger.info(f"ğŸ“± {self.platform_name} í¬ë¡¤ë§ ì¤‘...")
            self.logger.info(f"   URL: {self.url}")

            await page.goto(self.url, wait_until='domcontentloaded', timeout=20000)
            await page.wait_for_selector('li.search_result_box', timeout=10000)
            await page.wait_for_timeout(1000)

            items = await page.query_selector_all('li.search_result_box')
            self.logger.info(f"   ì‘í’ˆ ìš”ì†Œ {len(items)}ê°œ ë°œê²¬")

            for item in items[:50]:
                try:
                    entry = await self._parse_item(item)
                    if entry:
                        rankings.append(entry)
                except Exception as e:
                    self.logger.debug(f"ì‘í’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

            # ìˆœìœ„ ì •ë ¬
            rankings.sort(key=lambda x: x['rank'])

            self.logger.info(f"   âœ… {self.platform_name}: {len(rankings)}ê°œ ì‘í’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            return rankings

        finally:
            await page.close()
            await context.close()

    async def _parse_item(self, item) -> Dict[str, Any]:
        """ê°œë³„ ë­í‚¹ ì•„ì´í…œ íŒŒì‹±"""

        # 1. ìˆœìœ„: .title_rank í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ
        rank_el = await item.query_selector('.title_rank')
        if not rank_el:
            return None
        rank_text = (await rank_el.inner_text()).strip()
        match = re.search(r'(\d+)ä½', rank_text)
        if not match:
            return None
        rank = int(match.group(1))

        # 2. ì œëª©: .search_result_box_right_sec1 a.title
        title = None
        title_el = await item.query_selector('.search_result_box_right_sec1 a.title')
        if title_el:
            title = (await title_el.inner_text()).strip()

        # fallback: img alt
        if not title:
            img_el = await item.query_selector('img.volume_img')
            if img_el:
                title = await img_el.get_attribute('alt')

        if not title:
            return None

        # 3. URL: a.title href
        url = ''
        if title_el:
            href = await title_el.get_attribute('href')
            if href:
                url = f"https://www.cmoa.jp{href}" if not href.startswith('http') else href

        # 4. ì¥ë¥´: "ã‚¸ãƒ£ãƒ³ãƒ«ï¼š" ë‹¤ìŒì˜ <a> íƒœê·¸
        genre = ''
        sec2 = await item.query_selector('.search_result_box_right_sec2')
        if sec2:
            sec2_html = await sec2.inner_html()
            genre_match = re.search(r'ã‚¸ãƒ£ãƒ³ãƒ«ï¼š\s*<a[^>]*>([^<]+)</a>', sec2_html)
            if genre_match:
                genre = genre_match.group(1).strip()

        # 5. ì¸ë„¤ì¼: data-src (lazy loading) â†’ src fallback
        thumbnail_url = ''
        thumb_el = await item.query_selector('img.volume_img')
        if thumb_el:
            # data-srcì— ì‹¤ì œ URLì´ ìˆìŒ (lazy loading)
            thumb_src = await thumb_el.get_attribute('data-src') or ''
            if not thumb_src:
                thumb_src = await thumb_el.get_attribute('src') or ''
            if thumb_src and 'loader.png' not in thumb_src:
                thumbnail_url = f"https:{thumb_src}" if thumb_src.startswith('//') else thumb_src

        return {
            'rank': rank,
            'title': title.strip(),
            'genre': genre,
            'url': url,
            'thumbnail_url': thumbnail_url,
        }


if __name__ == "__main__":
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("ì½”ë¯¹ì‹œëª¨ì•„ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)

            try:
                agent = CmoaAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~5ìœ„):")
                    for item in result.data[:5]:
                        print(f"  {item['rank']}ìœ„: {item['title'][:40]}")
                        print(f"    ì¥ë¥´: {item['genre']}")
                        print(f"    URL: {item['url']}")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
