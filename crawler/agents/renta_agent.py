"""
ë Œíƒ€ (Renta!) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- SSR ë°©ì‹ (HTML ì§ì ‘ ë Œë”ë§)
- IP ì œí•œ ì—†ìŒ
- img.c-contents_cover ì…€ë ‰í„°ë¡œ ì¸ë„¤ì¼ ì¶”ì¶œ
- lazyload â†’ data-srcì— ì‹¤ì œ URL
- ì¥ë¥´ë³„ ë­í‚¹: ê°™ì€ í˜ì´ì§€(ranking_c.htm)ì— ì„¹ì…˜ë³„ë¡œ ë‚˜ë‰¨ (h2 + swiper)
"""

import re
from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class RentaAgent(CrawlerAgent):
    """ë Œíƒ€ ë§ˆì´ë„ˆì¹˜ ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    # ì¥ë¥´ë³„ ë­í‚¹ ë§¤í•‘
    # ê°™ì€ ranking_c.htm í˜ì´ì§€ ë‚´ì— h2 ì„¹ì…˜ìœ¼ë¡œ êµ¬ë¶„ë¨
    # section_id: í˜ì´ì§€ ë‚´ <section> ë˜ëŠ” <div> id
    GENRE_RANKINGS = {
        '': {'name': 'ì¢…í•©', 'path': '/renta/sc/frm/page/ranking_c.htm'},
        'ã‚¿ãƒ†ã‚³ãƒŸ': {'name': 'íƒ€í…Œì½”ë¯¸(ì›¹íˆ°)', 'section_keyword': 'ã‚¿ãƒ†ã‚³ãƒŸ'},
    }

    def __init__(self):
        super().__init__(
            platform_id='renta',
            platform_name='ë Œíƒ€ (Renta!)',
            url='https://renta.papy.co.jp/renta/sc/frm/page/ranking_c.htm'
        )
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """ë Œíƒ€ ì¢…í•© + ã‚¿ãƒ†ã‚³ãƒŸ ë­í‚¹ í¬ë¡¤ë§"""
        ctx = await browser.new_context(
            locale='ja-JP',
            viewport={'width': 1366, 'height': 768},
            ignore_https_errors=True,
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '
                       'AppleWebKit/537.36 (KHTML, like Gecko) '
                       'Chrome/120.0.0.0 Safari/537.36',
        )
        page = await ctx.new_page()
        all_rankings = []

        try:
            self.logger.info(f"ğŸ“± ë Œíƒ€ [ì¢…í•©] í¬ë¡¤ë§ ì¤‘... â†’ {self.url}")

            await page.goto(self.url, wait_until='domcontentloaded', timeout=30000)
            await page.wait_for_timeout(5000)

            # DOM ê¸°ë°˜ ì¶”ì¶œ (ì¸ë„¤ì¼ í¬í•¨)
            rankings = await self._extract_via_dom(page)

            # í´ë°±: JS evaluate
            if len(rankings) < 10:
                self.logger.info("   DOM íŒŒì‹± ë¶€ì¡±, JS evaluate ì‹œë„...")
                rankings = await self._extract_via_js(page)

            all_rankings = rankings[:100]
            self.genre_results[''] = all_rankings
            self.logger.info(f"   âœ… [ì¢…í•©]: {len(all_rankings)}ê°œ ì‘í’ˆ")

            # ===== ã‚¿ãƒ†ã‚³ãƒŸ ì„¹ì…˜ í¬ë¡¤ë§ =====
            self.logger.info(f"ğŸ“± ë Œíƒ€ [ã‚¿ãƒ†ã‚³ãƒŸ] í¬ë¡¤ë§ ì¤‘...")
            tatekomi_rankings = await self._extract_section(page, 'ã‚¿ãƒ†ã‚³ãƒŸ')

            if len(tatekomi_rankings) < 5:
                # í´ë°±: ã‚¿ãƒ†ã‚³ãƒŸ ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤ í›„ ì¬ì‹œë„
                self.logger.info("   ã‚¿ãƒ†ã‚³ãƒŸ ì„¹ì…˜ ìŠ¤í¬ë¡¤ í›„ ì¬ì‹œë„...")
                try:
                    await page.evaluate("""() => {
                        const h2 = Array.from(document.querySelectorAll('h2'))
                            .find(h => h.textContent.includes('ã‚¿ãƒ†ã‚³ãƒŸ'));
                        if (h2) h2.scrollIntoView({behavior: 'instant'});
                    }""")
                    await page.wait_for_timeout(3000)
                    tatekomi_rankings = await self._extract_section(page, 'ã‚¿ãƒ†ã‚³ãƒŸ')
                except Exception:
                    pass

            self.genre_results['ã‚¿ãƒ†ã‚³ãƒŸ'] = tatekomi_rankings[:100]
            self.logger.info(f"   âœ… [ã‚¿ãƒ†ã‚³ãƒŸ]: {len(tatekomi_rankings)}ê°œ ì‘í’ˆ")

            return all_rankings

        finally:
            await page.close()
            await ctx.close()

    async def _extract_section(self, page, section_keyword: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¥ë¥´ ì„¹ì…˜(h2 ê¸°ì¤€)ì—ì„œ ì‘í’ˆ ì¶”ì¶œ"""
        items = await page.evaluate("""(keyword) => {
            const results = [];

            // h2 íƒœê·¸ì—ì„œ í•´ë‹¹ ì¥ë¥´ ì„¹ì…˜ ì°¾ê¸°
            const allH2 = document.querySelectorAll('h2');
            let targetH2 = null;
            for (const h2 of allH2) {
                if (h2.textContent.includes(keyword + ' ãƒ©ãƒ³ã‚­ãƒ³ã‚°') ||
                    h2.textContent.includes(keyword + 'ãƒ©ãƒ³ã‚­ãƒ³ã‚°') ||
                    h2.textContent.trim().startsWith(keyword)) {
                    targetH2 = h2;
                    break;
                }
            }

            if (!targetH2) return results;

            // h2ì˜ ë¶€ëª¨ section ë˜ëŠ” ê°€ê¹Œìš´ ì»¨í…Œì´ë„ˆì—ì„œ ì‘í’ˆ ì°¾ê¸°
            // êµ¬ì¡°: section > div.c-innerwrap_side > h2 + div(swiper)
            const section = targetH2.closest('section') || targetH2.parentElement;
            if (!section) return results;

            // section ë‚´ì˜ ëª¨ë“  li.swiper-slideì—ì„œ ì‘í’ˆ ì¶”ì¶œ
            const slides = section.querySelectorAll('li.swiper-slide, li');
            let rank = 0;

            for (const li of slides) {
                const img = li.querySelector('img.c-contents_cover, img[class*="cover"], img[data-src]');
                if (!img) continue;

                const src = img.getAttribute('data-src') || img.getAttribute('src') || '';
                if (!src || src.includes('space.gif') || src.includes('blank') || src.includes('icon')) continue;

                const alt = img.getAttribute('alt') || '';
                let title = alt.replace(/ã®è¡¨ç´™$/, '').trim();

                if (!title || title.length < 2) {
                    const a = li.querySelector('a[href*="/frm/item/"]');
                    if (a) title = a.textContent.trim();
                }
                if (!title || title.length < 2) continue;

                const linkEl = li.querySelector('a[href*="/frm/item/"]');
                const href = linkEl ? linkEl.getAttribute('href') : '';
                const fullUrl = href ? (href.startsWith('http') ? href : 'https://renta.papy.co.jp' + href) : '';

                const thumbUrl = src.startsWith('http') ? src : (src.startsWith('//') ? 'https:' + src : 'https://renta.papy.co.jp' + src);

                rank++;
                if (rank <= 100) {
                    results.push({
                        rank: rank,
                        title: title,
                        url: fullUrl,
                        thumbnail_url: thumbUrl,
                    });
                }
            }
            return results;
        }""", section_keyword)

        return [
            {
                'rank': item['rank'],
                'title': item['title'],
                'genre': section_keyword,
                'url': item.get('url', ''),
                'thumbnail_url': item.get('thumbnail_url', ''),
            }
            for item in items[:100]
        ]

    async def _extract_via_dom(self, page) -> List[Dict[str, Any]]:
        """DOMì—ì„œ ì§ì ‘ ì¶”ì¶œ (img.c-contents_cover ì‚¬ìš©)"""
        items = await page.evaluate("""() => {
            const results = [];
            // renta: li.swiper-slide ì•ˆì— img.c-contents_cover
            const slides = document.querySelectorAll('li.swiper-slide, li');
            let rank = 0;

            for (const li of slides) {
                const img = li.querySelector('img.c-contents_cover, img[class*="cover"]');
                if (!img) continue;

                const src = img.getAttribute('data-src') || img.getAttribute('src') || '';
                if (!src || src.includes('space.gif') || src.includes('blank')) continue;

                const alt = img.getAttribute('alt') || '';
                // alt: "ã‚¿ã‚¤ãƒˆãƒ«ã®è¡¨ç´™" â†’ ã‚¿ã‚¤ãƒˆãƒ«
                let title = alt.replace(/ã®è¡¨ç´™$/, '').trim();

                // ë§í¬ì—ì„œ íƒ€ì´í‹€ ì¶”ì¶œ ì‹œë„
                if (!title || title.length < 2) {
                    const a = li.querySelector('a[href*="/frm/item/"]');
                    if (a) title = a.textContent.trim();
                }
                if (!title || title.length < 2) continue;

                const linkEl = li.querySelector('a[href*="/frm/item/"]');
                const href = linkEl ? linkEl.getAttribute('href') : '';
                const fullUrl = href ? (href.startsWith('http') ? href : 'https://renta.papy.co.jp' + href) : 'https://renta.papy.co.jp';

                const thumbUrl = src.startsWith('http') ? src : (src.startsWith('//') ? 'https:' + src : 'https://renta.papy.co.jp' + src);

                rank++;
                if (rank <= 100) {
                    results.push({
                        rank: rank,
                        title: title,
                        url: fullUrl,
                        thumbnail_url: thumbUrl,
                    });
                }
            }
            return results;
        }""")

        return [
            {
                'rank': item['rank'],
                'title': item['title'],
                'genre': '',
                'url': item.get('url', ''),
                'thumbnail_url': item.get('thumbnail_url', ''),
            }
            for item in items[:100]
        ]

    async def _extract_via_js(self, page) -> List[Dict[str, Any]]:
        """JavaScript evaluateë¡œ ì§ì ‘ ì¶”ì¶œ (í´ë°±)"""
        items = await page.evaluate("""() => {
            const results = [];
            const sections = document.querySelectorAll('ul');
            let rank = 0;

            sections.forEach(ul => {
                const lis = ul.querySelectorAll('li');
                lis.forEach(li => {
                    const a = li.querySelector('a[href*="/frm/item/"]');
                    if (!a) return;

                    const title = a.textContent.trim();
                    if (!title || title.length < 2) return;

                    const href = a.getAttribute('href') || '';
                    const img = li.querySelector('img');
                    const thumbSrc = img ? (img.getAttribute('data-src') || img.getAttribute('src') || '') : '';

                    rank++;
                    if (rank <= 100) {
                        results.push({
                            rank: rank,
                            title: title,
                            url: href.startsWith('http') ? href : 'https://renta.papy.co.jp' + href,
                            thumbnail_url: thumbSrc.startsWith('http') ? thumbSrc : (thumbSrc.startsWith('/') ? 'https://renta.papy.co.jp' + thumbSrc : ''),
                        });
                    }
                });
            });

            return results;
        }""")

        return [
            {
                'rank': item['rank'],
                'title': item['title'],
                'genre': '',
                'url': item.get('url', ''),
                'thumbnail_url': item.get('thumbnail_url', ''),
            }
            for item in items[:100]
        ]

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ ëª¨ë‘ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        # ì¢…í•© ë­í‚¹ ì €ì¥
        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
            for item in data if item.get('thumbnail_url')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta, date=date, sub_category='')
        backup_to_json(date, self.platform_id, data)

        # ì¥ë¥´ë³„ ë­í‚¹ ì €ì¥
        for genre_key, rankings in self.genre_results.items():
            if genre_key == '':
                continue
            genre_name = self.GENRE_RANKINGS[genre_key]['name']
            save_rankings(date, self.platform_id, rankings, sub_category=genre_key)
            genre_meta = [
                {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
                 'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
                for item in rankings if item.get('thumbnail_url')
            ]
            if genre_meta:
                save_works_metadata(self.platform_id, genre_meta, date=date, sub_category=genre_key)
            self.logger.info(f"   ğŸ’¾ [{genre_name}]: {len(rankings)}ê°œ ì €ì¥")
