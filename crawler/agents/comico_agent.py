"""
ì½”ë¯¸ì½” (comico) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- CSR ë°©ì‹ (Playwright í•„ìˆ˜, Vue.js SPA)
- IP ì œí•œ ì—†ìŒ
- ë°ì¼ë¦¬ ë­í‚¹ ê¸°ë³¸, ì¥ë¥´ íƒ­ ì „í™˜ ê°€ëŠ¥
- ì…€ë ‰í„°: div.thumbnail êµ¬ì¡° (ìˆœìœ„+ì œëª©+ì‘ê°€)
- ì¥ë¥´ë³„ ë­í‚¹: ?currentItemCode= íŒŒë¼ë¯¸í„°
"""

import re
from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class ComicoAgent(CrawlerAgent):
    """ì½”ë¯¸ì½” ë°ì¼ë¦¬ ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    GENRE_RANKINGS = {
        '': {'name': 'ì¢…í•©(ë°ì¼ë¦¬)', 'code': ''},
        'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼': {'name': 'íŒíƒ€ì§€', 'code': 'fantasy'},
        'æ‹æ„›': {'name': 'ì—°ì• ', 'code': 'romance'},
        'BL': {'name': 'BL', 'code': 'bl'},
        'ãƒ‰ãƒ©ãƒ': {'name': 'ë“œë¼ë§ˆ', 'code': 'drama'},
        'æ—¥å¸¸': {'name': 'ì¼ìƒ', 'code': 'daily_life'},
        'TL': {'name': 'TL', 'code': 'tl'},
        'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': {'name': 'ì•¡ì…˜', 'code': 'action'},
        'å­¦åœ’': {'name': 'í•™ì›', 'code': 'school'},
        'ãƒŸã‚¹ãƒ†ãƒªãƒ¼': {'name': 'ë¯¸ìŠ¤í„°ë¦¬', 'code': 'mystery'},
        'ãƒ›ãƒ©ãƒ¼': {'name': 'í˜¸ëŸ¬', 'code': 'horror'},
    }

    def __init__(self):
        super().__init__(
            platform_id='comico',
            platform_name='ì½”ë¯¸ì½” (ë°ì¼ë¦¬)',
            url='https://www.comico.jp/menu/all_comic/ranking'
        )
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """ì½”ë¯¸ì½” ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ í¬ë¡¤ë§"""
        page = await browser.new_page()
        all_rankings = []

        try:
            for genre_key, genre_info in self.GENRE_RANKINGS.items():
                label = genre_info['name']
                code = genre_info['code']

                if code:
                    url = f'{self.url}?currentItemCode={code}'
                else:
                    url = self.url

                self.logger.info(f"ğŸ“± ì½”ë¯¸ì½” [{label}] í¬ë¡¤ë§ ì¤‘... â†’ {url}")

                await page.goto(url, wait_until='domcontentloaded', timeout=20000)
                await page.wait_for_timeout(5000)

                # DOM ê¸°ë°˜ íŒŒì‹± (ì¸ë„¤ì¼ í¬í•¨)
                rankings = await self._parse_dom_rankings(page, genre_key)

                self.genre_results[genre_key] = rankings
                self.logger.info(f"   âœ… [{label}]: {len(rankings)}ê°œ ì‘í’ˆ")

                if genre_key == '':
                    all_rankings = rankings

            return all_rankings

        finally:
            await page.close()

    async def _parse_dom_rankings(self, page, genre_key: str) -> List[Dict[str, Any]]:
        """DOMì—ì„œ ë­í‚¹ ì•„ì´í…œ + ì¸ë„¤ì¼ ì¶”ì¶œ"""
        items = await page.evaluate("""() => {
            const results = [];
            // comico: li ì•ˆì— a > div.thumbnail > figure > img êµ¬ì¡°
            const listItems = document.querySelectorAll('li');
            let rank = 0;

            for (const li of listItems) {
                const img = li.querySelector('div.thumbnail img, figure img');
                const captionEl = li.querySelector('div.caption, div.title, a');
                if (!img || !captionEl) continue;

                const src = img.getAttribute('src') || '';
                const alt = img.getAttribute('alt') || '';
                // comico ì´ë¯¸ì§€ëŠ” images.comico.io ë„ë©”ì¸
                if (!src.includes('comico')) continue;

                const titleEl = li.querySelector('div.caption h2, div.caption p, div.title');
                const title = titleEl ? titleEl.textContent.trim() : alt;
                if (!title || title.length < 2) continue;

                const linkEl = li.querySelector('a[href*="/comic/"]');
                const href = linkEl ? linkEl.getAttribute('href') : '';
                const fullUrl = href ? (href.startsWith('http') ? href : 'https://www.comico.jp' + href) : '';

                rank++;
                if (rank <= 100) {
                    results.push({
                        rank: rank,
                        title: title,
                        url: fullUrl || 'https://www.comico.jp/menu/all_comic/ranking',
                        thumbnail_url: src,
                    });
                }
            }
            return results;
        }""")

        rankings = []
        for item in items[:100]:
            rankings.append({
                'rank': item['rank'],
                'title': item['title'],
                'genre': genre_key,
                'url': item.get('url', ''),
                'thumbnail_url': item.get('thumbnail_url', ''),
            })

        # DOM íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ í´ë°±
        if len(rankings) < 5:
            self.logger.info("   DOM íŒŒì‹± ë¶€ì¡±, í…ìŠ¤íŠ¸ í´ë°±...")
            body_text = await page.inner_text('body')
            rankings = self._parse_text_rankings(body_text, genre_key)

        return rankings

    def _parse_text_rankings(self, body_text: str, genre_key: str) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë­í‚¹ ì•„ì´í…œ ì¶”ì¶œ (í´ë°±)"""
        lines = [l.strip() for l in body_text.split('\n') if l.strip()]
        rankings = []
        i = 0

        while i < len(lines) and len(rankings) < 100:
            line = lines[i]
            if line.isdigit() and 1 <= int(line) <= 100:
                rank = int(line)
                if i + 1 < len(lines):
                    title = lines[i + 1].strip()
                    if len(title) >= 2 and title not in ['ä½', 'ç„¡æ–™', 'New', 'æ¬¡ã¸']:
                        rankings.append({
                            'rank': rank,
                            'title': title,
                            'genre': genre_key,
                            'url': f'https://www.comico.jp/menu/all_comic/ranking',
                            'thumbnail_url': '',
                        })
            i += 1

        return rankings

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ ëª¨ë‘ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
            for item in data if item.get('thumbnail_url')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta, date=date, sub_category='')
        backup_to_json(date, self.platform_id, data)

        for genre_key, rankings in self.genre_results.items():
            if genre_key == '':
                continue
            genre_name = self.GENRE_RANKINGS[genre_key]['name']
            save_rankings(date, self.platform_id, rankings, sub_category=genre_key)
            genre_meta = [
                {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
                 'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
                for item in rankings if item.get('thumbnail_url')
            ]
            if genre_meta:
                save_works_metadata(self.platform_id, genre_meta, date=date, sub_category=genre_key)
            self.logger.info(f"   ğŸ’¾ [{genre_name}]: {len(rankings)}ê°œ ì €ì¥")
