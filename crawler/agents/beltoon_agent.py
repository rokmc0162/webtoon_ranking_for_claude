"""
ë²¨íˆ° (BeLTOON) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- CSR ë°©ì‹ (Next.js + styled-components)
- IP ì œí•œ ì—†ìŒ
- ë°ì¼ë¦¬ ë­í‚¹ (ìˆœìœ„ + íƒ€ì´í‹€ + ì¡°íšŒìˆ˜ + ì‘ê°€)
- ì¥ë¥´ í•„í„° (ë¡œë§¨ìŠ¤, BL, íŒíƒ€ì§€, ë“œë¼ë§ˆ, GL, ì†Œë…€ë§Œí™”)
"""

import re
from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class BeltoonAgent(CrawlerAgent):
    """ë²¨íˆ° ë°ì¼ë¦¬ ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    GENRE_RANKINGS = {
        '': {'name': 'ì¢…í•©(ë°ì¼ë¦¬)', 'filter': ''},
    }

    def __init__(self):
        super().__init__(
            platform_id='beltoon',
            platform_name='ë²¨íˆ° (BeLTOON)',
            url='https://www.beltoon.jp/app/all/ranking'
        )
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """ë²¨íˆ° ë°ì¼ë¦¬ ë­í‚¹ í¬ë¡¤ë§"""
        page = await browser.new_page()
        all_rankings = []

        try:
            self.logger.info(f"ğŸ“± ë²¨íˆ° [ì¢…í•©] í¬ë¡¤ë§ ì¤‘... â†’ {self.url}")

            await page.goto(self.url, wait_until='domcontentloaded', timeout=20000)
            await page.wait_for_timeout(5000)

            # ìŠ¤í¬ë¡¤ ë‹¤ìš´ìœ¼ë¡œ lazy loading íŠ¸ë¦¬ê±°
            for _ in range(10):
                await page.evaluate('window.scrollBy(0, 1000)')
                await page.wait_for_timeout(500)

            # í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹± (ìˆœìœ„ + íƒ€ì´í‹€ + ì¡°íšŒìˆ˜ + ì‘ê°€ íŒ¨í„´)
            body_text = await page.inner_text('body')
            rankings = self._parse_text_rankings(body_text)

            all_rankings = rankings
            self.genre_results[''] = rankings
            self.logger.info(f"   âœ… [ì¢…í•©]: {len(rankings)}ê°œ ì‘í’ˆ")

            return all_rankings

        finally:
            await page.close()

    def _parse_text_rankings(self, body_text: str) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë­í‚¹ ì•„ì´í…œ ì¶”ì¶œ

        ë²¨íˆ° íŒ¨í„´:
        ìˆœìœ„ë²ˆí˜¸
        íƒ€ì´í‹€
        ì¡°íšŒìˆ˜(Në§Œ ë˜ëŠ” N.Në§Œ) ë˜ëŠ” "ë¬´ë£Œì¦ëŸ‰ì¤‘" ë“±
        ì‘ê°€ëª…
        """
        lines = [l.strip() for l in body_text.split('\n') if l.strip()]
        rankings = []

        # "ãƒ‡ã‚¤ãƒªãƒ¼" í…ìŠ¤íŠ¸ ì´í›„ ì‹œì‘
        start_idx = 0
        for i, line in enumerate(lines):
            if line == 'ãƒ‡ã‚¤ãƒªãƒ¼':
                start_idx = i + 1
                break

        i = start_idx
        while i < len(lines) and len(rankings) < 100:
            line = lines[i]

            # ìˆœìœ„ ë²ˆí˜¸ ê°ì§€
            if line.isdigit() and 1 <= int(line) <= 100:
                rank = int(line)

                # ìˆœìœ„ ë³€ë™ ë²ˆí˜¸ ê±´ë„ˆë›°ê¸° (ë‹¤ìŒ ì¤„ì´ ë˜ ìˆ«ìì´ë©´ ë³€ë™í­)
                j = i + 1
                while j < len(lines) and lines[j].isdigit():
                    j += 1

                # íƒ€ì´í‹€
                if j < len(lines):
                    title = lines[j].strip()
                    if (len(title) >= 2 and
                            title not in ['ãƒã‚§ãƒƒã‚¯è§£é™¤', 'çµã‚Šè¾¼ã¿', '...', 'ãƒ­ãƒãƒ³ã‚¹',
                                          'BL', 'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼', 'ãƒ‰ãƒ©ãƒ', 'GL', 'å°‘å¥³ãƒãƒ³ã‚¬'] and
                            not title.startswith('(')):

                        rankings.append({
                            'rank': rank,
                            'title': title,
                            'genre': '',
                            'url': 'https://www.beltoon.jp/app/all/ranking',
                            'thumbnail_url': '',
                        })
                        i = j + 1
                        continue

            i += 1

        return rankings

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ë­í‚¹ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
            for item in data if item.get('title')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta, date=date, sub_category='')
        backup_to_json(date, self.platform_id, data)
