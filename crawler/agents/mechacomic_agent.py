"""
ë©”ì± ì½”ë¯¹ (ã‚ã¡ã‚ƒã‚³ãƒŸãƒƒã‚¯) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- CSR ë°©ì‹ (Playwright í•„ìˆ˜)
- Tailwind CSS ê¸°ë°˜ UI (2026ë…„ ë¦¬ë‰´ì–¼ ë²„ì „ ëŒ€ì‘)
- ë‹¨ì¼ í˜ì´ì§€ì— ì „ì²´ ë­í‚¹ í‘œì‹œ (ul.grid > li êµ¬ì¡°)
- IP ì œí•œ ì—†ìŒ (í•œêµ­ì—ì„œë„ ì ‘ê·¼ ê°€ëŠ¥)
- ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹: ?category= íŒŒë¼ë¯¸í„°ë¡œ êµ¬ë¶„
"""

import re
from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class MechacomicAgent(CrawlerAgent):
    """ë©”ì± ì½”ë¯¹ íŒë§¤ ë­í‚¹ + ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    # ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ ë§¤í•‘ (URL: ?genre=N)
    GENRE_RANKINGS = {
        '': {'name': 'ì¢…í•©', 'genre_id': ''},
        'å°‘å¥³': {'name': 'ì†Œë…€', 'genre_id': '2'},
        'å¥³æ€§': {'name': 'ì—¬ì„±', 'genre_id': '4'},
        'å°‘å¹´': {'name': 'ì†Œë…„', 'genre_id': '1'},
        'é’å¹´': {'name': 'ì²­ë…„', 'genre_id': '3'},
        'ãƒãƒ¼ãƒ¬ã‚¯ã‚¤ãƒ³': {'name': 'í• ë¦¬í€¸', 'genre_id': '40'},
    }

    def __init__(self):
        super().__init__(
            platform_id='mechacomic',
            platform_name='ë©”ì± ì½”ë¯¹ (íŒë§¤)',
            url='https://mechacomic.jp/sales_rankings/current'
        )
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """
        ë©”ì± ì½”ë¯¹ ì¢…í•© + ì¹´í…Œê³ ë¦¬ë³„ íŒë§¤ ë­í‚¹ í¬ë¡¤ë§

        DOM êµ¬ì¡° (2026ë…„ Tailwind CSS ë¦¬ë‰´ì–¼ ë²„ì „):
        <ul class="grid grid-cols-1 lg:grid-cols-2">
          <li>
            <div class="flex gap-2.5 ...">
              <div>  <!-- ì´ë¯¸ì§€ ì˜ì—­ -->
                <a href="/books/{id}"><img alt="ì œëª©" ...></a>
              </div>
              <div>  <!-- ì •ë³´ ì˜ì—­ -->
                <span class="... font-bold">1ä½</span>
                <a href="/books/{id}" class="font-bold text-link">ì œëª©</a>
                <div class="text-[12px]">ì‘ê°€ëª…</div>
                <span class="inline-flex ...">ì¥ë¥´íƒœê·¸</span>
              </div>
            </div>
          </li>
        </ul>
        """
        page = await browser.new_page()
        all_rankings = []

        try:
            for genre_key, genre_info in self.GENRE_RANKINGS.items():
                label = genre_info['name']
                genre_id = genre_info['genre_id']
                self.logger.info(f"ğŸ“± ë©”ì± ì½”ë¯¹ [{label}] í¬ë¡¤ë§ ì¤‘...")

                rankings = await self._crawl_category(page, genre_id, genre_key)
                self.genre_results[genre_key] = rankings
                self.logger.info(f"   âœ… [{label}]: {len(rankings)}ê°œ ì‘í’ˆ")

                # ì¢…í•© ë­í‚¹ì€ ë°˜í™˜ê°’ìœ¼ë¡œ ì‚¬ìš©
                if genre_key == '':
                    all_rankings = rankings

            return all_rankings

        finally:
            await page.close()

    async def _crawl_category(self, page, genre_id: str, genre_key: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ë­í‚¹ í¬ë¡¤ë§ (3í˜ì´ì§€, ìƒìœ„ 50ê°œ)"""
        rankings = []

        for page_num in range(1, 4):
            # URL êµ¬ì„±: genre + page íŒŒë¼ë¯¸í„°
            params = []
            if genre_id:
                params.append(f'genre={genre_id}')
            if page_num > 1:
                params.append(f'page={page_num}')
            url = f'{self.url}?{"&".join(params)}' if params else self.url

            await page.goto('about:blank')
            await page.goto(url, wait_until='domcontentloaded', timeout=30000)
            await page.wait_for_selector('ul.grid li', timeout=15000)
            await page.wait_for_timeout(2000)

            items = await page.query_selector_all('ul.grid.grid-cols-1 > li')

            for item in items:
                try:
                    entry = await self._parse_item(item)
                    if entry:
                        if genre_key and not entry['genre']:
                            entry['genre'] = genre_key
                        rankings.append(entry)
                except Exception as e:
                    self.logger.debug(f"ê°œë³„ ì‘í’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

        rankings.sort(key=lambda x: x['rank'])
        return rankings[:50]

    async def _parse_item(self, item) -> Dict[str, Any]:
        """ê°œë³„ ë­í‚¹ ì•„ì´í…œ íŒŒì‹±"""

        # 1. ìˆœìœ„ ì¶”ì¶œ: <span class="... font-bold">Nä½</span>
        rank_spans = await item.query_selector_all('span')
        rank = None
        for span in rank_spans:
            text = await span.inner_text()
            text = text.strip()
            match = re.match(r'^(\d+)ä½$', text)
            if match:
                rank = int(match.group(1))
                break

        if rank is None:
            return None

        # 2. ì œëª© ì¶”ì¶œ: <a class="font-bold text-link ...">ì œëª©</a>
        title = None
        title_links = await item.query_selector_all('a.font-bold')
        for link in title_links:
            cls = await link.get_attribute('class') or ''
            if 'text-link' in cls:
                title = (await link.inner_text()).strip()
                break

        if not title:
            # fallback: ì´ë¯¸ì§€ alt ì†ì„±ì—ì„œ ì œëª© ì¶”ì¶œ
            img = await item.query_selector('img[alt]:not([alt=""])')
            if img:
                alt = await img.get_attribute('alt')
                # ì•„ì´ì½˜ ì´ë¯¸ì§€ ì œì™¸ (ã‚ªãƒªã‚¸ãƒŠãƒ«, ç‹¬å å…ˆè¡Œ, ç¶šè©± ë“±)
                if alt and len(alt) > 3 and alt not in [
                    'ã‚ªãƒªã‚¸ãƒŠãƒ«', 'ç‹¬å å…ˆè¡Œ', 'ç¶šè©±', 'æ¯æ—¥ç„¡æ–™ãƒ—ãƒ©ã‚¹'
                ]:
                    title = alt.strip()

        if not title:
            return None

        # 3. URL ì¶”ì¶œ: /books/{id}
        url = ''
        book_link = await item.query_selector('a[href*="/books/"]')
        if book_link:
            href = await book_link.get_attribute('href')
            if href:
                url = f"https://mechacomic.jp{href}" if not href.startswith('http') else href

        # 4. ì¥ë¥´ íƒœê·¸ ì¶”ì¶œ: <span class="inline-flex items-center ...">ì¥ë¥´</span>
        genres = []
        genre_spans = await item.query_selector_all('span.inline-flex')
        for gs in genre_spans:
            genre_text = (await gs.inner_text()).strip()
            if genre_text:
                genres.append(genre_text)

        # ì²« ë²ˆì§¸ ì¥ë¥´ë¥¼ ë©”ì¸ ì¥ë¥´ë¡œ ì‚¬ìš©
        genre = genres[0] if genres else ''

        # 5. ì¸ë„¤ì¼: /images/book/ ê²½ë¡œì˜ ì‹¤ì œ í‘œì§€ ì´ë¯¸ì§€ (ì•„ì´ì½˜ ì œì™¸)
        thumbnail_url = ''
        all_imgs = await item.query_selector_all('img[alt]:not([alt=""])')
        for img in all_imgs:
            src = await img.get_attribute('src') or ''
            if '/images/book/' in src:
                thumbnail_url = src
                break

        return {
            'rank': rank,
            'title': title,
            'genre': genre,
            'url': url,
            'thumbnail_url': thumbnail_url,
        }

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ì¢…í•© + ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ ëª¨ë‘ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        # ì¢…í•© ë­í‚¹ ì €ì¥
        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', '')}
            for item in data if item.get('thumbnail_url')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta)
        backup_to_json(date, self.platform_id, data)

        # ì¹´í…Œê³ ë¦¬ë³„ ë­í‚¹ ì €ì¥
        for genre_key, rankings in self.genre_results.items():
            if genre_key == '':
                continue
            genre_name = self.GENRE_RANKINGS[genre_key]['name']
            save_rankings(date, self.platform_id, rankings, sub_category=genre_key)
            genre_meta = [
                {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
                 'url': item.get('url', '')}
                for item in rankings if item.get('thumbnail_url')
            ]
            if genre_meta:
                save_works_metadata(self.platform_id, genre_meta)
            self.logger.info(f"   ğŸ’¾ [{genre_name}]: {len(rankings)}ê°œ ì €ì¥")


if __name__ == "__main__":
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("ë©”ì± ì½”ë¯¹ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)

            try:
                agent = MechacomicAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~5ìœ„):")
                    for item in result.data[:5]:
                        print(f"  {item['rank']}ìœ„: {item['title']}")
                        print(f"    ì¥ë¥´: {item['genre']}")
                        print(f"    URL: {item['url']}")

                    # ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ìš”ì•½
                    print(f"\nì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼:")
                    for gkey, rankings in agent.genre_results.items():
                        label = agent.GENRE_RANKINGS[gkey]['name']
                        print(f"  [{label}]: {len(rankings)}ê°œ")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
