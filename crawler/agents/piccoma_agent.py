"""
í”½ì½”ë§ˆ (ãƒ”ãƒƒã‚³ãƒ) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- SSR ë°©ì‹ (HTMLì— ëª¨ë“  ë°ì´í„° í¬í•¨)
- SMARTOON ì¢…í•© ë­í‚¹ í¬ë¡¤ë§
- ì¼ë³¸ IP í•„ìˆ˜
- ì…€ë ‰í„°: .PCM-productTile ul > li (2026ë…„ í˜„ì¬ êµ¬ì¡°)
- ì¥ë¥´: ë­í‚¹ í˜ì´ì§€ì— ì—†ìŒ â†’ ê°œë³„ ì‘í’ˆ í˜ì´ì§€ JSON-LDì—ì„œ ìˆ˜ì§‘ í›„ ìºì‹œ
"""

from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent
from crawler.db import get_works_genres, save_work_genre, update_rankings_genre
from crawler.utils import translate_genre


class PiccomaAgent(CrawlerAgent):
    """í”½ì½”ë§ˆ SMARTOON ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    # ì¥ë¥´ë³„ ë­í‚¹ URL ë§¤í•‘
    GENRE_RANKINGS = {
        '': {'name': 'ì´í•©', 'path': '/web/ranking/S/P/0'},
        'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼': {'name': 'íŒíƒ€ì§€', 'path': '/web/ranking/S/P/2'},
        'æ‹æ„›': {'name': 'ì—°ì• ', 'path': '/web/ranking/S/P/1'},
        'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': {'name': 'ì•¡ì…˜', 'path': '/web/ranking/S/P/5'},
        'ãƒ‰ãƒ©ãƒ': {'name': 'ë“œë¼ë§ˆ', 'path': '/web/ranking/S/P/3'},
        'ãƒ›ãƒ©ãƒ¼ãƒ»ãƒŸã‚¹ãƒ†ãƒªãƒ¼': {'name': 'í˜¸ëŸ¬/ë¯¸ìŠ¤í„°ë¦¬', 'path': '/web/ranking/S/P/7'},
        'è£ç¤¾ä¼šãƒ»ã‚¢ãƒ³ã‚°ãƒ©': {'name': 'ë’·ì„¸ê³„/ì–¸ë”ê·¸ë¼ìš´ë“œ', 'path': '/web/ranking/S/P/9'},
        'ã‚¹ãƒãƒ¼ãƒ„': {'name': 'ìŠ¤í¬ì¸ ', 'path': '/web/ranking/S/P/6'},
        'ã‚°ãƒ«ãƒ¡': {'name': 'ìš”ë¦¬', 'path': '/web/ranking/S/P/10'},
        'æ—¥å¸¸': {'name': 'ì¼ìƒ', 'path': '/web/ranking/S/P/4'},
        'TL': {'name': 'TL', 'path': '/web/ranking/S/P/13'},
        'BL': {'name': 'BL', 'path': '/web/ranking/S/P/14'},
    }

    def __init__(self):
        super().__init__(
            platform_id='piccoma',
            platform_name='í”½ì½”ë§ˆ (SMARTOON)',
            url='https://piccoma.com/web/ranking/S/P/0'
        )
        # ì¥ë¥´ë³„ í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ (orchestratorì—ì„œ ì°¸ì¡°)
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """í”½ì½”ë§ˆ SMARTOON ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ í¬ë¡¤ë§"""
        page = await browser.new_page()
        all_rankings = []

        try:
            for genre_key, genre_info in PiccomaAgent.GENRE_RANKINGS.items():
                url = f"https://piccoma.com{genre_info['path']}"
                label = genre_info['name']

                self.logger.info(f"ğŸ“± í”½ì½”ë§ˆ [{label}] í¬ë¡¤ë§ ì¤‘... â†’ {url}")

                await page.goto(url, wait_until='domcontentloaded', timeout=30000)
                await page.wait_for_selector('.PCM-productTile ul > li', timeout=10000)
                await page.wait_for_timeout(500)

                items = await page.query_selector_all('.PCM-productTile ul > li')
                rankings = []
                for item in items[:50]:
                    try:
                        entry = await self._parse_item(item)
                        if entry:
                            # ì¥ë¥´ë³„ ë­í‚¹ì€ ì¥ë¥´ë¥¼ URLì˜ ì¹´í…Œê³ ë¦¬ë¡œ ì„¤ì •
                            if genre_key and not entry['genre']:
                                entry['genre'] = genre_key
                            rankings.append(entry)
                    except Exception:
                        continue

                self.logger.info(f"   âœ… [{label}]: {len(rankings)}ê°œ ì‘í’ˆ")
                self.genre_results[genre_key] = rankings

                # ì¢…í•© ë­í‚¹ì€ all_rankingsì— í¬í•¨ (ê¸°ì¡´ í˜¸í™˜)
                if genre_key == '':
                    all_rankings = rankings

            # ì¥ë¥´ ìˆ˜ì§‘: ì¢…í•© ë­í‚¹ ì‘í’ˆë§Œ (ì¥ë¥´ë³„ì€ ì´ë¯¸ ì¥ë¥´ í™•ì •)
            await self._fill_genres(browser, all_rankings)

            return all_rankings

        finally:
            await page.close()

    async def _parse_item(self, item) -> Dict[str, Any]:
        """ê°œë³„ ë­í‚¹ ì•„ì´í…œ íŒŒì‹±"""

        # 1. ìˆœìœ„: .PCM-rankingProduct_rankNum
        rank_el = await item.query_selector('.PCM-rankingProduct_rankNum')
        if not rank_el:
            return None
        rank_text = (await rank_el.inner_text()).strip()
        try:
            rank = int(rank_text)
        except ValueError:
            return None

        # 2. ì œëª©: img[alt] (ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤)
        title = None
        img_el = await item.query_selector('img[alt]')
        if img_el:
            title = await img_el.get_attribute('alt')

        # fallback: .PCM-l_rankingProduct_name
        if not title:
            name_el = await item.query_selector('.PCM-l_rankingProduct_name')
            if name_el:
                title = (await name_el.inner_text()).strip()

        if not title:
            return None

        # 3. URL: a[href*="/web/product"]
        url = ''
        link_el = await item.query_selector('a[href*="/web/product"]')
        if link_el:
            href = await link_el.get_attribute('href')
            if href:
                url = f"https://piccoma.com{href}" if not href.startswith('http') else href

        # 4. ì¥ë¥´: í”½ì½”ë§ˆ ë­í‚¹ í˜ì´ì§€ì—ëŠ” ì¥ë¥´ ì •ë³´ê°€ ì—†ìŒ (ë¹ˆ ë¬¸ìì—´)
        genre = ''

        # 5. ì¸ë„¤ì¼: data-original (lazy loading) â†’ src fallback
        thumbnail_url = ''
        if img_el:
            # data-originalì— ì‹¤ì œ URLì´ ìˆìŒ (lazy loading)
            thumb_src = await img_el.get_attribute('data-original') or ''
            if not thumb_src:
                thumb_src = await img_el.get_attribute('src') or ''
            if thumb_src and 'ph_cover.png' not in thumb_src:
                thumbnail_url = f"https:{thumb_src}" if thumb_src.startswith('//') else thumb_src

        return {
            'rank': rank,
            'title': title.strip(),
            'genre': genre,
            'url': url,
            'thumbnail_url': thumbnail_url,
        }

    async def _fill_genres(self, browser: Browser, rankings: List[Dict[str, Any]]):
        """
        ì¥ë¥´ê°€ ì—†ëŠ” ì‘í’ˆì— ëŒ€í•´ ê°œë³„ í˜ì´ì§€ì—ì„œ ì¥ë¥´ ìˆ˜ì§‘ í›„ ìºì‹œ

        - works í…Œì´ë¸”ì— ì´ë¯¸ ì¥ë¥´ê°€ ìˆìœ¼ë©´ ìºì‹œì—ì„œ ê°€ì ¸ì˜´
        - ì—†ìœ¼ë©´ ê°œë³„ ì‘í’ˆ í˜ì´ì§€ì˜ JSON-LDì—ì„œ category ì¶”ì¶œ
        """
        # 1. ìºì‹œëœ ì¥ë¥´ ë¡œë“œ
        genre_cache = get_works_genres('piccoma')
        need_fetch = []

        for item in rankings:
            title = item['title']
            if title in genre_cache:
                item['genre'] = genre_cache[title]
            elif item['url']:
                need_fetch.append(item)

        if not need_fetch:
            self.logger.info(f"   ğŸ“š ì¥ë¥´: ì „ë¶€ ìºì‹œ ì ì¤‘ ({len(rankings)}ê°œ)")
            return

        self.logger.info(f"   ğŸ“š ì¥ë¥´ ìˆ˜ì§‘: {len(need_fetch)}ê°œ ì‘í’ˆ í˜ì´ì§€ ë°©ë¬¸ í•„ìš”")

        # 2. ê°œë³„ í˜ì´ì§€ ë°©ë¬¸í•˜ì—¬ ì¥ë¥´ ì¶”ì¶œ
        page = await browser.new_page()
        fetched = 0
        try:
            for item in need_fetch:
                try:
                    genre = await self._fetch_genre_from_page(page, item['url'])
                    if genre:
                        item['genre'] = genre
                        save_work_genre('piccoma', item['title'], genre)
                        genre_kr = translate_genre(genre)
                        update_rankings_genre('piccoma', item['title'], genre, genre_kr)
                        fetched += 1
                except Exception as e:
                    self.logger.warning(f"   ì¥ë¥´ ìˆ˜ì§‘ ì‹¤íŒ¨ ({item['title']}): {e}")
                    continue
        finally:
            await page.close()

        self.logger.info(f"   ğŸ“š ì¥ë¥´ ìˆ˜ì§‘ ì™„ë£Œ: {fetched}/{len(need_fetch)}ê°œ ì„±ê³µ")

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ ëª¨ë‘ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        # ì¢…í•© ë­í‚¹ ì €ì¥
        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
            for item in data if item.get('thumbnail_url')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta, date=date, sub_category='')
        backup_to_json(date, self.platform_id, data)

        # ì¥ë¥´ë³„ ë­í‚¹ ì €ì¥
        for genre_key, rankings in self.genre_results.items():
            if genre_key == '':  # ì¢…í•©ì€ ìœ„ì—ì„œ ì´ë¯¸ ì €ì¥
                continue
            genre_name = PiccomaAgent.GENRE_RANKINGS[genre_key]['name']
            save_rankings(date, self.platform_id, rankings, sub_category=genre_key)
            genre_meta = [
                {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
                 'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
                for item in rankings if item.get('thumbnail_url')
            ]
            if genre_meta:
                save_works_metadata(self.platform_id, genre_meta, date=date, sub_category=genre_key)
            self.logger.info(f"   ğŸ’¾ [{genre_name}]: {len(rankings)}ê°œ ì €ì¥")

    async def _fetch_genre_from_page(self, page, url: str) -> str:
        """ê°œë³„ ì‘í’ˆ í˜ì´ì§€ì—ì„œ BreadcrumbListì˜ position 2(ì¥ë¥´)ë¥¼ ì¶”ì¶œ"""
        await page.goto(url, wait_until='domcontentloaded', timeout=15000)

        genre = await page.evaluate('''
            () => {
                const scripts = document.querySelectorAll('script[type="application/ld+json"]');
                for (const s of scripts) {
                    try {
                        const data = JSON.parse(s.textContent);
                        if (data["@type"] === "BreadCrumbList" && data.itemListElement) {
                            for (const item of data.itemListElement) {
                                if (item.position === 2) return item.name;
                            }
                        }
                    } catch(e) {}
                }
                return "";
            }
        ''')
        return genre or ''


if __name__ == "__main__":
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("í”½ì½”ë§ˆ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)

            try:
                agent = PiccomaAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~5ìœ„):")
                    for item in result.data[:5]:
                        print(f"  {item['rank']}ìœ„: {item['title']}")
                        print(f"    URL: {item['url']}")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
