"""
í”½ì½”ë§ˆ (ãƒ”ãƒƒã‚³ãƒ) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- SSR ë°©ì‹ (HTMLì— ëª¨ë“  ë°ì´í„° í¬í•¨, ê°€ì¥ ì‰¬ì›€)
- SMARTOON ì¢…í•© ë­í‚¹ í¬ë¡¤ë§
- ì¼ë³¸ IP í•„ìˆ˜
"""

from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent
from crawler.utils import get_korean_title, is_riverse_title, translate_genre


class PiccomaAgent(CrawlerAgent):
    """í”½ì½”ë§ˆ SMARTOON ì¢…í•© ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    def __init__(self):
        super().__init__(
            platform_id='piccoma',
            platform_name='í”½ì½”ë§ˆ (SMARTOON)',
            url='https://piccoma.com/web/ranking/S/P/0'
        )

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """
        í”½ì½”ë§ˆ SMARTOON ì¢…í•© ë­í‚¹ 50ìœ„ í¬ë¡¤ë§

        Args:
            browser: Playwright ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤

        Returns:
            [{'rank': 1, 'title': 'ì œëª©', 'genre': 'ì¥ë¥´', 'url': 'http://...'}, ...]
        """
        page = await browser.new_page()
        rankings = []

        try:
            self.logger.info(f"ğŸ“± {self.platform_name} í¬ë¡¤ë§ ì¤‘...")
            self.logger.info(f"   URL: {self.url}")

            # SSR ë°©ì‹ì´ë¯€ë¡œ domcontentloadedë©´ ì¶©ë¶„
            await page.goto(self.url, wait_until='domcontentloaded', timeout=30000)

            # SSRì´ë¯€ë¡œ ì¦‰ì‹œ ë°ì´í„° ìˆìŒ, í•˜ì§€ë§Œ ì•ˆì „í•˜ê²Œ ëŒ€ê¸°
            await page.wait_for_selector(
                '.PCM-productList_item, .ranking-item, article',
                timeout=10000
            )

            # ì‘í’ˆ ìš”ì†Œ ì¶”ì¶œ
            items = await page.query_selector_all(
                '.PCM-productList_item, .ranking-item, article, li'
            )

            self.logger.info(f"   ì‘í’ˆ ìš”ì†Œ {len(items)}ê°œ ë°œê²¬")

            for i, item in enumerate(items[:50], 1):  # ìƒìœ„ 50ê°œë§Œ
                try:
                    # ìˆœìœ„ ì¶”ì¶œ
                    rank = await self._extract_rank(item, i)

                    # ì œëª© ì¶”ì¶œ
                    title = await self._extract_title(item)

                    if not title:
                        continue

                    # URL ì¶”ì¶œ
                    url_full = await self._extract_url(item)

                    # ì¥ë¥´ ì¶”ì¶œ
                    genre = await self._extract_genre(item)

                    # í•œêµ­ì–´ ì œëª© ë° ë¦¬ë²„ìŠ¤ ì—¬ë¶€ í™•ì¸
                    title_kr = get_korean_title(title)
                    is_riverse = is_riverse_title(title)
                    genre_kr = translate_genre(genre)

                    rankings.append({
                        'rank': rank,
                        'title': title.strip(),
                        'title_kr': title_kr,
                        'genre': genre.strip() if genre else "",
                        'genre_kr': genre_kr,
                        'url': url_full,
                        'is_riverse': is_riverse
                    })

                except Exception as e:
                    self.logger.debug(f"{i}ë²ˆì§¸ ì‘í’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

            self.logger.info(f"   âœ… {self.platform_name}: {len(rankings)}ê°œ ì‘í’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            return rankings

        finally:
            await page.close()

    async def _extract_rank(self, item, fallback: int) -> int:
        """ìˆœìœ„ ì¶”ì¶œ (selector ìš°ì„ , fallbackì€ ìˆœì„œ)"""
        rank_elem = await item.query_selector('.rank, .ranking-number, .number')

        if rank_elem:
            rank_text = await rank_elem.inner_text()
            try:
                return int(rank_text.strip().replace('ä½', '').replace('#', ''))
            except ValueError:
                pass

        return fallback

    async def _extract_title(self, item) -> str:
        """ì œëª© ì¶”ì¶œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)"""
        # Method 1: title class
        title_elem = await item.query_selector('.PCM-product-title, .title, h3, h2')
        if title_elem:
            title = await title_elem.inner_text()
            if title:
                return title.strip()

        # Method 2: link attributes
        link_elem = await item.query_selector('a')
        if link_elem:
            title = await link_elem.get_attribute('aria-label')
            if title:
                return title.strip()

            title = await link_elem.get_attribute('title')
            if title:
                return title.strip()

        # Method 3: ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì‹±
        text = await item.inner_text()
        lines = [l.strip() for l in text.split('\n') if l.strip()]
        for line in lines:
            if len(line) > 3 and 'ä½' not in line and '#' not in line:
                return line

        return ""

    async def _extract_url(self, item) -> str:
        """URL ì¶”ì¶œ"""
        link_elem = await item.query_selector('a')
        if not link_elem:
            return ""

        url_path = await link_elem.get_attribute('href')
        if not url_path:
            return ""

        if url_path.startswith('http'):
            return url_path
        else:
            return f"https://piccoma.com{url_path}"

    async def _extract_genre(self, item) -> str:
        """ì¥ë¥´ ì¶”ì¶œ"""
        # Method 1: selector
        genre_elem = await item.query_selector('.genre, .category, .tag')
        if genre_elem:
            genre = await genre_elem.inner_text()
            if genre:
                return genre.strip()

        # Method 2: í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
        text = await item.inner_text()
        return self._extract_genre_from_text(text)

    def _extract_genre_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì¥ë¥´ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        genres = [
            'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼', 'æ‹æ„›', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³', 'ãƒ‰ãƒ©ãƒ', 'ãƒ›ãƒ©ãƒ¼', 'ãƒŸã‚¹ãƒ†ãƒªãƒ¼',
            'ã‚³ãƒ¡ãƒ‡ã‚£', 'ã‚µã‚¹ãƒšãƒ³ã‚¹', 'SF', 'å­¦åœ’', 'ã‚¹ãƒãƒ¼ãƒ„', 'ã‚°ãƒ«ãƒ¡',
            'æ—¥å¸¸', 'BL', 'TL', 'ç•°ä¸–ç•Œ', 'è»¢ç”Ÿ', 'å¾©è®', 'ãƒãƒˆãƒ«', 'æ­´å²'
        ]

        for genre in genres:
            if genre in text:
                return genre

        return ""


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("í”½ì½”ë§ˆ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=False)

            try:
                agent = PiccomaAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~3ìœ„):")
                    for item in result.data[:3]:
                        print(f"  {item['rank']}ìœ„: {item['title']}")
                        if item['title_kr']:
                            print(f"    í•œêµ­ì–´: {item['title_kr']}")
                        print(f"    ì¥ë¥´: {item['genre']} ({item['genre_kr']})")
                        print(f"    ë¦¬ë²„ìŠ¤: {item['is_riverse']}")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
