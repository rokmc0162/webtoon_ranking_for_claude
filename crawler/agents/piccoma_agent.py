"""
í”½ì½”ë§ˆ (ãƒ”ãƒƒã‚³ãƒ) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- SSR ë°©ì‹ (HTMLì— ëª¨ë“  ë°ì´í„° í¬í•¨)
- SMARTOON ì¢…í•© ë­í‚¹ í¬ë¡¤ë§
- ì¼ë³¸ IP í•„ìˆ˜
- ì…€ë ‰í„°: .PCM-productTile ul > li (2026ë…„ í˜„ì¬ êµ¬ì¡°)
- ì¥ë¥´: ë­í‚¹ í˜ì´ì§€ì— ì—†ìŒ â†’ ê°œë³„ ì‘í’ˆ í˜ì´ì§€ JSON-LDì—ì„œ ìˆ˜ì§‘ í›„ ìºì‹œ
"""

from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent
from crawler.db import get_works_genres, save_work_genre, update_rankings_genre
from crawler.utils import translate_genre


class PiccomaAgent(CrawlerAgent):
    """í”½ì½”ë§ˆ SMARTOON ì¢…í•© ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    def __init__(self):
        super().__init__(
            platform_id='piccoma',
            platform_name='í”½ì½”ë§ˆ (SMARTOON)',
            url='https://piccoma.com/web/ranking/S/P/0'
        )

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """
        í”½ì½”ë§ˆ SMARTOON ì¢…í•© ë­í‚¹ 50ìœ„ í¬ë¡¤ë§

        DOM êµ¬ì¡°:
        <div class="PCM-productTile PCOM-component">
          <ul>
            <li>
              <a href="/web/product/{id}">
                <img alt="ì œëª©" src="...">
                <div class="PCM-rankingProduct_rankNum">1</div>
                <div class="PCM-rankingProduct_rankChangeNum">11</div>
                <div class="PCM-l_rankingProduct_name">ì œëª©</div>
                <div class="PCM-l_rankingProduct_author">ì‘ê°€ëª…</div>
              </a>
            </li>
          </ul>
        </div>
        """
        page = await browser.new_page()
        rankings = []

        try:
            self.logger.info(f"ğŸ“± {self.platform_name} í¬ë¡¤ë§ ì¤‘...")
            self.logger.info(f"   URL: {self.url}")

            await page.goto(self.url, wait_until='domcontentloaded', timeout=30000)

            # ë­í‚¹ ë¦¬ìŠ¤íŠ¸ ëŒ€ê¸°
            await page.wait_for_selector('.PCM-productTile ul > li', timeout=10000)
            await page.wait_for_timeout(1000)

            # ì‘í’ˆ ì•„ì´í…œ ì¶”ì¶œ (ì •í™•íˆ 50ê°œ)
            items = await page.query_selector_all('.PCM-productTile ul > li')
            self.logger.info(f"   ì‘í’ˆ ìš”ì†Œ {len(items)}ê°œ ë°œê²¬")

            for item in items[:50]:
                try:
                    entry = await self._parse_item(item)
                    if entry:
                        rankings.append(entry)
                except Exception as e:
                    self.logger.debug(f"ì‘í’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

            self.logger.info(f"   âœ… {self.platform_name}: {len(rankings)}ê°œ ì‘í’ˆ ìˆ˜ì§‘ ì™„ë£Œ")

            # ì¥ë¥´ ìˆ˜ì§‘: ìºì‹œì— ì—†ëŠ” ì‘í’ˆë§Œ ê°œë³„ í˜ì´ì§€ ë°©ë¬¸
            await self._fill_genres(browser, rankings)

            return rankings

        finally:
            await page.close()

    async def _parse_item(self, item) -> Dict[str, Any]:
        """ê°œë³„ ë­í‚¹ ì•„ì´í…œ íŒŒì‹±"""

        # 1. ìˆœìœ„: .PCM-rankingProduct_rankNum
        rank_el = await item.query_selector('.PCM-rankingProduct_rankNum')
        if not rank_el:
            return None
        rank_text = (await rank_el.inner_text()).strip()
        try:
            rank = int(rank_text)
        except ValueError:
            return None

        # 2. ì œëª©: img[alt] (ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤)
        title = None
        img_el = await item.query_selector('img[alt]')
        if img_el:
            title = await img_el.get_attribute('alt')

        # fallback: .PCM-l_rankingProduct_name
        if not title:
            name_el = await item.query_selector('.PCM-l_rankingProduct_name')
            if name_el:
                title = (await name_el.inner_text()).strip()

        if not title:
            return None

        # 3. URL: a[href*="/web/product"]
        url = ''
        link_el = await item.query_selector('a[href*="/web/product"]')
        if link_el:
            href = await link_el.get_attribute('href')
            if href:
                url = f"https://piccoma.com{href}" if not href.startswith('http') else href

        # 4. ì¥ë¥´: í”½ì½”ë§ˆ ë­í‚¹ í˜ì´ì§€ì—ëŠ” ì¥ë¥´ ì •ë³´ê°€ ì—†ìŒ (ë¹ˆ ë¬¸ìì—´)
        genre = ''

        # 5. ì¸ë„¤ì¼: data-original (lazy loading) â†’ src fallback
        thumbnail_url = ''
        if img_el:
            # data-originalì— ì‹¤ì œ URLì´ ìˆìŒ (lazy loading)
            thumb_src = await img_el.get_attribute('data-original') or ''
            if not thumb_src:
                thumb_src = await img_el.get_attribute('src') or ''
            if thumb_src and 'ph_cover.png' not in thumb_src:
                thumbnail_url = f"https:{thumb_src}" if thumb_src.startswith('//') else thumb_src

        return {
            'rank': rank,
            'title': title.strip(),
            'genre': genre,
            'url': url,
            'thumbnail_url': thumbnail_url,
        }

    async def _fill_genres(self, browser: Browser, rankings: List[Dict[str, Any]]):
        """
        ì¥ë¥´ê°€ ì—†ëŠ” ì‘í’ˆì— ëŒ€í•´ ê°œë³„ í˜ì´ì§€ì—ì„œ ì¥ë¥´ ìˆ˜ì§‘ í›„ ìºì‹œ

        - works í…Œì´ë¸”ì— ì´ë¯¸ ì¥ë¥´ê°€ ìˆìœ¼ë©´ ìºì‹œì—ì„œ ê°€ì ¸ì˜´
        - ì—†ìœ¼ë©´ ê°œë³„ ì‘í’ˆ í˜ì´ì§€ì˜ JSON-LDì—ì„œ category ì¶”ì¶œ
        """
        # 1. ìºì‹œëœ ì¥ë¥´ ë¡œë“œ
        genre_cache = get_works_genres('piccoma')
        need_fetch = []

        for item in rankings:
            title = item['title']
            if title in genre_cache:
                item['genre'] = genre_cache[title]
            elif item['url']:
                need_fetch.append(item)

        if not need_fetch:
            self.logger.info(f"   ğŸ“š ì¥ë¥´: ì „ë¶€ ìºì‹œ ì ì¤‘ ({len(rankings)}ê°œ)")
            return

        self.logger.info(f"   ğŸ“š ì¥ë¥´ ìˆ˜ì§‘: {len(need_fetch)}ê°œ ì‘í’ˆ í˜ì´ì§€ ë°©ë¬¸ í•„ìš”")

        # 2. ê°œë³„ í˜ì´ì§€ ë°©ë¬¸í•˜ì—¬ ì¥ë¥´ ì¶”ì¶œ
        page = await browser.new_page()
        fetched = 0
        try:
            for item in need_fetch:
                try:
                    genre = await self._fetch_genre_from_page(page, item['url'])
                    if genre:
                        item['genre'] = genre
                        save_work_genre('piccoma', item['title'], genre)
                        genre_kr = translate_genre(genre)
                        update_rankings_genre('piccoma', item['title'], genre, genre_kr)
                        fetched += 1
                except Exception as e:
                    self.logger.warning(f"   ì¥ë¥´ ìˆ˜ì§‘ ì‹¤íŒ¨ ({item['title']}): {e}")
                    continue
        finally:
            await page.close()

        self.logger.info(f"   ğŸ“š ì¥ë¥´ ìˆ˜ì§‘ ì™„ë£Œ: {fetched}/{len(need_fetch)}ê°œ ì„±ê³µ")

    async def _fetch_genre_from_page(self, page, url: str) -> str:
        """ê°œë³„ ì‘í’ˆ í˜ì´ì§€ì—ì„œ BreadcrumbListì˜ position 2(ì¥ë¥´)ë¥¼ ì¶”ì¶œ"""
        await page.goto(url, wait_until='domcontentloaded', timeout=15000)

        genre = await page.evaluate('''
            () => {
                const scripts = document.querySelectorAll('script[type="application/ld+json"]');
                for (const s of scripts) {
                    try {
                        const data = JSON.parse(s.textContent);
                        if (data["@type"] === "BreadCrumbList" && data.itemListElement) {
                            for (const item of data.itemListElement) {
                                if (item.position === 2) return item.name;
                            }
                        }
                    } catch(e) {}
                }
                return "";
            }
        ''')
        return genre or ''


if __name__ == "__main__":
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("í”½ì½”ë§ˆ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)

            try:
                agent = PiccomaAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~5ìœ„):")
                    for item in result.data[:5]:
                        print(f"  {item['rank']}ìœ„: {item['title']}")
                        print(f"    URL: {item['url']}")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
