"""
ë¼ì¸ë§ê°€ (LINE ãƒãƒ³ã‚¬) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- SSR+CSR í•˜ì´ë¸Œë¦¬ë“œ (domcontentloadedë¡œ ì¶©ë¶„)
- ì¼ë³¸ IP í•„ìˆ˜
- 90ê°œ ì‘í’ˆì´ í•œ í˜ì´ì§€ì— ë¡œë“œë¨ (ìŠ¤í¬ë¡¤ ë¶ˆí•„ìš”)
- ì¢…í•©: /periodic/gender_ranking?gender=0 (ol > li, MdCMN14Num ìˆœìœ„ ìˆìŒ)
- ì¥ë¥´ë³„: /genre_list?genre_id=XXXX (ìˆœìœ„ ë²ˆí˜¸ ì—†ìŒ, ìœ„ì¹˜ ê¸°ë°˜)
"""

from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class LinemangaAgent(CrawlerAgent):
    """ë¼ì¸ë§ê°€ ì›¹ ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    # ì¥ë¥´ë³„ ë­í‚¹ URL ë§¤í•‘ (/genre_list?genre_id=XXXX)
    GENRE_RANKINGS = {
        '': {'name': 'ì´í•©'},
        'ãƒãƒˆãƒ«ãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': {'name': 'ë°°í‹€/ì•¡ì…˜', 'genre_id': '0001'},
        'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ãƒ»SF': {'name': 'íŒíƒ€ì§€/SF', 'genre_id': '0002'},
        'æ‹æ„›': {'name': 'ì—°ì• ', 'genre_id': '0003'},
        'ã‚¹ãƒãƒ¼ãƒ„': {'name': 'ìŠ¤í¬ì¸ ', 'genre_id': '0004'},
        'ãƒŸã‚¹ãƒ†ãƒªãƒ¼ãƒ»ãƒ›ãƒ©ãƒ¼': {'name': 'ë¯¸ìŠ¤í„°ë¦¬/í˜¸ëŸ¬', 'genre_id': '0005'},
        'è£ç¤¾ä¼šãƒ»ã‚¢ãƒ³ã‚°ãƒ©': {'name': 'ë’·ì„¸ê³„/ì–¸ë”', 'genre_id': '0006'},
        'ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ': {'name': 'íœ´ë¨¼ë“œë¼ë§ˆ', 'genre_id': '0007'},
        'æ­´å²ãƒ»æ™‚ä»£': {'name': 'ì—­ì‚¬/ì‹œëŒ€', 'genre_id': '0008'},
        'ã‚³ãƒ¡ãƒ‡ã‚£ãƒ»ã‚®ãƒ£ã‚°': {'name': 'ì½”ë¯¸ë””/ê°œê·¸', 'genre_id': '0009'},
        'ãã®ä»–': {'name': 'ê¸°íƒ€', 'genre_id': 'ffff'},
    }

    def __init__(self):
        super().__init__(
            platform_id='linemanga',
            platform_name='ë¼ì¸ë§ê°€ (ì›¹ ì¢…í•©)',
            url='https://manga.line.me/periodic/gender_ranking?gender=0'
        )
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """
        ë¼ì¸ë§ê°€ ì›¹ ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ í¬ë¡¤ë§

        ì¢…í•© DOM êµ¬ì¡° (/periodic/gender_ranking):
        <div class="MdCMN05List">
          <ol>
            <li>
              <a href="/product/periodic?id=..." title="ì œëª©">
                <span class="MdCMN14Num">1</span>
                <div class="MdCMN06Img"><img alt="ì œëª©" src="..."></div>
                <span class="mdCMN05Ttl">ì œëª©</span>
                <ul class="mdCMN05InfoList">
                  <li>ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ãƒ»SF</li>
                </ul>
              </a>
            </li>
          </ol>
        </div>

        ì¥ë¥´ë³„ DOM êµ¬ì¡° (/genre_list?genre_id=XXXX):
        <div class="MdCMN05List">
          <li>
            <a href="/product/periodic?id=..." title="ì œëª©">
              <div class="MdCMN06Img"><img alt="ì œëª©" src="..."></div>
              <span class="mdCMN05Ttl">ì œëª©</span>
            </a>
          </li>
        </div>
        (ìˆœìœ„ ë²ˆí˜¸ ì—†ìŒ - ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ìˆœìœ„ ê²°ì •)
        """
        page = await browser.new_page()
        all_rankings = []

        try:
            # ===== 1. ì¢…í•© ë­í‚¹ (/periodic/gender_ranking) =====
            self.logger.info(f"ğŸ“± ë¼ì¸ë§ê°€ [ì´í•©] í¬ë¡¤ë§ ì¤‘...")
            self.logger.info(f"   URL: {self.url}")

            await page.goto(self.url, wait_until='domcontentloaded', timeout=30000)

            try:
                await page.wait_for_selector('.MdCMN05List ol > li', timeout=15000)
            except Exception:
                content = await page.content()
                if 'æ—¥æœ¬å›½å†…' in content or len(content) < 1000:
                    self.logger.error("âŒ ì¼ë³¸ IPê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    raise Exception("IP ì œí•œ: ì¼ë³¸ IP í•„ìš”")
                raise

            await page.wait_for_timeout(2000)

            items = await page.query_selector_all('.MdCMN05List ol > li')
            self.logger.info(f"   ì‘í’ˆ ìš”ì†Œ {len(items)}ê°œ ë°œê²¬")

            for item in items[:50]:
                try:
                    entry = await self._parse_item(item)
                    if entry:
                        all_rankings.append(entry)
                except Exception as e:
                    self.logger.debug(f"ì‘í’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

            self.logger.info(f"   âœ… [ì´í•©]: {len(all_rankings)}ê°œ ì‘í’ˆ")
            self.genre_results[''] = all_rankings

            # ===== 2. ì¥ë¥´ë³„ ë­í‚¹ (/genre_list?genre_id=XXXX í˜ì´ì§€ ì§ì ‘ í¬ë¡¤ë§) =====
            for genre_key, genre_info in self.GENRE_RANKINGS.items():
                if genre_key == '':
                    continue

                genre_id = genre_info['genre_id']
                label = genre_info['name']
                self.logger.info(f"ğŸ“± ë¼ì¸ë§ê°€ [{label}] í¬ë¡¤ë§ ì¤‘...")

                try:
                    rankings = await self._crawl_genre_page(page, genre_id, genre_key)
                    self.genre_results[genre_key] = rankings
                    self.logger.info(f"   âœ… [{label}]: {len(rankings)}ê°œ ì‘í’ˆ")
                except Exception as e:
                    self.logger.warning(f"   âš ï¸ [{label}] ì‹¤íŒ¨: {e}")
                    self.genre_results[genre_key] = []

            return all_rankings

        finally:
            await page.close()

    async def _parse_item(self, item) -> Dict[str, Any]:
        """ê°œë³„ ë­í‚¹ ì•„ì´í…œ íŒŒì‹±"""

        # ë§í¬ ìš”ì†Œ
        link = await item.query_selector('a[href*="/product/"]')
        if not link:
            return None

        # 1. ìˆœìœ„: <span class="MdCMN14Num">N</span>
        rank_el = await item.query_selector('.MdCMN14Num')
        if not rank_el:
            return None
        rank_text = (await rank_el.inner_text()).strip()
        try:
            rank = int(rank_text)
        except ValueError:
            return None

        # 2. ì œëª©: title ì†ì„± ë˜ëŠ” <span class="mdCMN05Ttl">
        title = await link.get_attribute('title')
        if not title:
            title_el = await item.query_selector('.mdCMN05Ttl')
            if title_el:
                title = (await title_el.inner_text()).strip()
        if not title:
            return None

        # 3. URL
        href = await link.get_attribute('href') or ''
        url = f"https://manga.line.me{href}" if href and not href.startswith('http') else href

        # 4. ì¥ë¥´: <ul class="mdCMN05InfoList"><li>ì¥ë¥´</li>...</ul>
        genre = ''
        genre_el = await item.query_selector('.mdCMN05InfoList li:first-child')
        if genre_el:
            genre = (await genre_el.inner_text()).strip()

        # 5. ì¸ë„¤ì¼: .MdCMN06Img img src
        thumbnail_url = ''
        thumb_img = await item.query_selector('.MdCMN06Img img')
        if thumb_img:
            thumbnail_url = await thumb_img.get_attribute('src') or ''

        return {
            'rank': rank,
            'title': title.strip(),
            'genre': genre,
            'url': url,
            'thumbnail_url': thumbnail_url,
        }

    async def _crawl_genre_page(self, page, genre_id: str, genre_key: str) -> List[Dict[str, Any]]:
        """ì¥ë¥´ë³„ ë­í‚¹ í˜ì´ì§€ ì§ì ‘ í¬ë¡¤ë§ (/genre_list?genre_id=XXXX)"""
        url = f"https://manga.line.me/genre_list?genre_id={genre_id}"

        await page.goto(url, wait_until='domcontentloaded', timeout=30000)
        await page.wait_for_selector('a[href*="/product/"]', timeout=15000)
        await page.wait_for_timeout(2000)

        # ì¥ë¥´ í˜ì´ì§€ì—ì„œ product ë§í¬ë¥¼ ê°€ì§„ ì•„ì´í…œ ì¶”ì¶œ
        # .MdCMN05List ë‚´ì˜ a[href*="/product/"] ìš”ì†Œë“¤
        product_links = await page.query_selector_all('.MdCMN05List a[href*="/product/"]')
        self.logger.info(f"   ìƒí’ˆ ë§í¬ {len(product_links)}ê°œ ë°œê²¬")

        rankings = []
        seen_titles = set()
        rank = 0

        for link in product_links:
            try:
                # ì œëª©: title ì†ì„±
                title = await link.get_attribute('title')
                if not title:
                    img = await link.query_selector('img')
                    if img:
                        title = await img.get_attribute('alt') or ''
                if not title or title in seen_titles:
                    continue

                seen_titles.add(title)
                rank += 1

                # URL
                href = await link.get_attribute('href') or ''
                item_url = f"https://manga.line.me{href}" if href and not href.startswith('http') else href

                # ì¸ë„¤ì¼
                thumbnail_url = ''
                thumb_img = await link.query_selector('.MdCMN06Img img')
                if thumb_img:
                    thumbnail_url = await thumb_img.get_attribute('src') or ''

                rankings.append({
                    'rank': rank,
                    'title': title.strip(),
                    'genre': genre_key,
                    'url': item_url,
                    'thumbnail_url': thumbnail_url,
                })

                if rank >= 50:
                    break

            except Exception as e:
                self.logger.debug(f"ì¥ë¥´ ì•„ì´í…œ íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue

        return rankings

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ ëª¨ë‘ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        # ì¢…í•© ë­í‚¹ ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', '')}
            for item in data if item.get('thumbnail_url')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta)
        backup_to_json(date, self.platform_id, data)

        # ì¥ë¥´ë³„ ë­í‚¹ ì €ì¥
        for genre_key, rankings in self.genre_results.items():
            if genre_key == '':
                continue
            genre_name = self.GENRE_RANKINGS[genre_key]['name']
            save_rankings(date, self.platform_id, rankings, sub_category=genre_key)
            genre_meta = [
                {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
                 'url': item.get('url', '')}
                for item in rankings if item.get('thumbnail_url')
            ]
            if genre_meta:
                save_works_metadata(self.platform_id, genre_meta)
            self.logger.info(f"   ğŸ’¾ [{genre_name}]: {len(rankings)}ê°œ ì €ì¥")


if __name__ == "__main__":
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("ë¼ì¸ë§ê°€ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)

            try:
                agent = LinemangaAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~5ìœ„):")
                    for item in result.data[:5]:
                        print(f"  {item['rank']}ìœ„: {item['title']}")
                        print(f"    ì¥ë¥´: {item['genre']}")
                        print(f"    URL: {item['url']}")

                    # ì¥ë¥´ë³„ ê²°ê³¼ ìš”ì•½
                    print(f"\nì¥ë¥´ë³„ ê²°ê³¼:")
                    for gkey, rankings in agent.genre_results.items():
                        label = agent.GENRE_RANKINGS[gkey]['name']
                        print(f"  [{label}]: {len(rankings)}ê°œ")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
