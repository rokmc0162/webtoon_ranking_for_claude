"""
ë¼ì¸ë§ê°€ (LINE ãƒãƒ³ã‚¬) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- SSR+CSR í•˜ì´ë¸Œë¦¬ë“œ (domcontentloadedë¡œ ì¶©ë¶„)
- ì¼ë³¸ IP í•„ìˆ˜
- 90ê°œ ì‘í’ˆì´ í•œ í˜ì´ì§€ì— ë¡œë“œë¨ (ìŠ¤í¬ë¡¤ ë¶ˆí•„ìš”)
- ì…€ë ‰í„°: .MdCMN05List ol > li (2026ë…„ í˜„ì¬ êµ¬ì¡°)
- ì¥ë¥´ë³„ ë­í‚¹: JSON API (/api/ranking/product_genre_weekly_ranking) í™œìš©
"""

import json
from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class LinemangaAgent(CrawlerAgent):
    """ë¼ì¸ë§ê°€ ì›¹ ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    # ì¥ë¥´ë³„ ë­í‚¹ URL ë§¤í•‘ (product_genre_weekly_ranking API)
    GENRE_RANKINGS = {
        '': {'name': 'ì´í•©'},
        'ãƒãƒˆãƒ«ãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': {'name': 'ë°°í‹€/ì•¡ì…˜', 'genre_id': '0001'},
        'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ãƒ»SF': {'name': 'íŒíƒ€ì§€/SF', 'genre_id': '0002'},
        'æ‹æ„›': {'name': 'ì—°ì• ', 'genre_id': '0003'},
        'ã‚¹ãƒãƒ¼ãƒ„': {'name': 'ìŠ¤í¬ì¸ ', 'genre_id': '0004'},
        'ãƒŸã‚¹ãƒ†ãƒªãƒ¼ãƒ»ãƒ›ãƒ©ãƒ¼': {'name': 'ë¯¸ìŠ¤í„°ë¦¬/í˜¸ëŸ¬', 'genre_id': '0005'},
        'è£ç¤¾ä¼šãƒ»ã‚¢ãƒ³ã‚°ãƒ©': {'name': 'ë’·ì„¸ê³„/ì–¸ë”', 'genre_id': '0006'},
        'ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ': {'name': 'íœ´ë¨¼ë“œë¼ë§ˆ', 'genre_id': '0007'},
        'æ­´å²ãƒ»æ™‚ä»£': {'name': 'ì—­ì‚¬/ì‹œëŒ€', 'genre_id': '0008'},
        'ã‚³ãƒ¡ãƒ‡ã‚£ãƒ»ã‚®ãƒ£ã‚°': {'name': 'ì½”ë¯¸ë””/ê°œê·¸', 'genre_id': '0009'},
        'BL': {'name': 'BL', 'genre_id': '0010'},
        'TL': {'name': 'TL', 'genre_id': '0011'},
        'ãã®ä»–': {'name': 'ê¸°íƒ€', 'genre_id': '0013'},
    }

    def __init__(self):
        super().__init__(
            platform_id='linemanga',
            platform_name='ë¼ì¸ë§ê°€ (ì›¹ ì¢…í•©)',
            url='https://manga.line.me/periodic/gender_ranking?gender=0'
        )
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """
        ë¼ì¸ë§ê°€ ì›¹ ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ í¬ë¡¤ë§

        DOM êµ¬ì¡° (ì¢…í•©):
        <div class="MdCMN05List">
          <ol>
            <li>
              <a href="/product/periodic?id=..." title="ì œëª©">
                <span class="MdCMN14Num">1</span>
                <div class="MdCMN06Img"><img alt="ì œëª©" src="..."></div>
                <span class="mdCMN05Ttl">ì œëª©</span>
                <ul class="mdCMN05InfoList">
                  <li>ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ãƒ»SF</li>
                  <li>æ¯é€±é‡‘æ›œæ›´æ–°</li>
                </ul>
              </a>
            </li>
          </ol>
        </div>
        """
        page = await browser.new_page()
        all_rankings = []

        try:
            # ===== 1. ì¢…í•© ë­í‚¹ (ê¸°ì¡´ ë°©ì‹: periodic/gender_ranking) =====
            self.logger.info(f"ğŸ“± ë¼ì¸ë§ê°€ [ì´í•©] í¬ë¡¤ë§ ì¤‘...")
            self.logger.info(f"   URL: {self.url}")

            await page.goto(self.url, wait_until='domcontentloaded', timeout=30000)

            try:
                await page.wait_for_selector('.MdCMN05List ol > li', timeout=15000)
            except Exception:
                content = await page.content()
                if 'æ—¥æœ¬å›½å†…' in content or len(content) < 1000:
                    self.logger.error("âŒ ì¼ë³¸ IPê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    raise Exception("IP ì œí•œ: ì¼ë³¸ IP í•„ìš”")
                raise

            await page.wait_for_timeout(2000)

            items = await page.query_selector_all('.MdCMN05List ol > li')
            self.logger.info(f"   ì‘í’ˆ ìš”ì†Œ {len(items)}ê°œ ë°œê²¬")

            for item in items[:50]:
                try:
                    entry = await self._parse_item(item)
                    if entry:
                        all_rankings.append(entry)
                except Exception as e:
                    self.logger.debug(f"ì‘í’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

            self.logger.info(f"   âœ… [ì´í•©]: {len(all_rankings)}ê°œ ì‘í’ˆ")
            self.genre_results[''] = all_rankings

            # ===== 2. ì¥ë¥´ë³„ ë­í‚¹ (JSON API: product_genre_weekly_ranking) =====
            for genre_key, genre_info in self.GENRE_RANKINGS.items():
                if genre_key == '':
                    continue

                genre_id = genre_info['genre_id']
                label = genre_info['name']
                self.logger.info(f"ğŸ“± ë¼ì¸ë§ê°€ [{label}] í¬ë¡¤ë§ ì¤‘...")

                try:
                    rankings = await self._crawl_genre_api(page, genre_id, genre_key)
                    self.genre_results[genre_key] = rankings
                    self.logger.info(f"   âœ… [{label}]: {len(rankings)}ê°œ ì‘í’ˆ")
                except Exception as e:
                    self.logger.warning(f"   âš ï¸ [{label}] ì‹¤íŒ¨: {e}")
                    self.genre_results[genre_key] = []

            return all_rankings

        finally:
            await page.close()

    async def _parse_item(self, item) -> Dict[str, Any]:
        """ê°œë³„ ë­í‚¹ ì•„ì´í…œ íŒŒì‹±"""

        # ë§í¬ ìš”ì†Œ
        link = await item.query_selector('a[href*="/product/"]')
        if not link:
            return None

        # 1. ìˆœìœ„: <span class="MdCMN14Num">N</span>
        rank_el = await item.query_selector('.MdCMN14Num')
        if not rank_el:
            return None
        rank_text = (await rank_el.inner_text()).strip()
        try:
            rank = int(rank_text)
        except ValueError:
            return None

        # 2. ì œëª©: title ì†ì„± ë˜ëŠ” <span class="mdCMN05Ttl">
        title = await link.get_attribute('title')
        if not title:
            title_el = await item.query_selector('.mdCMN05Ttl')
            if title_el:
                title = (await title_el.inner_text()).strip()
        if not title:
            return None

        # 3. URL
        href = await link.get_attribute('href') or ''
        url = f"https://manga.line.me{href}" if href and not href.startswith('http') else href

        # 4. ì¥ë¥´: <ul class="mdCMN05InfoList"><li>ì¥ë¥´</li>...</ul>
        genre = ''
        genre_el = await item.query_selector('.mdCMN05InfoList li:first-child')
        if genre_el:
            genre = (await genre_el.inner_text()).strip()

        # 5. ì¸ë„¤ì¼: .MdCMN06Img img src
        thumbnail_url = ''
        thumb_img = await item.query_selector('.MdCMN06Img img')
        if thumb_img:
            thumbnail_url = await thumb_img.get_attribute('src') or ''

        return {
            'rank': rank,
            'title': title.strip(),
            'genre': genre,
            'url': url,
            'thumbnail_url': thumbnail_url,
        }

    async def _crawl_genre_api(self, page, genre_id: str, genre_key: str) -> List[Dict[str, Any]]:
        """JSON APIë¡œ ì¥ë¥´ë³„ ë­í‚¹ ìˆ˜ì§‘ (product_genre_weekly_ranking)"""
        api_url = f"https://manga.line.me/api/ranking/product_genre_weekly_ranking?genre_id={genre_id}&page=1&rows=50"

        # ì´ë¯¸ manga.line.me ë„ë©”ì¸ì— ìˆìœ¼ë¯€ë¡œ fetch ì‚¬ìš© ê°€ëŠ¥
        json_data = await page.evaluate('''
            async (url) => {
                const resp = await fetch(url);
                return await resp.json();
            }
        ''', api_url)

        rankings = []
        rows = json_data.get('result', {}).get('rows', [])
        for i, row in enumerate(rows[:50], 1):
            title = row.get('name', '')
            if not title:
                continue

            product_id = row.get('id', '')
            url = f"https://manga.line.me/book/product_list?product_id={product_id}" if product_id else ''
            thumbnail = row.get('thumbnail', '')

            rankings.append({
                'rank': row.get('rank', i),
                'title': title,
                'genre': genre_key,
                'url': url,
                'thumbnail_url': thumbnail,
            })

        return rankings

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ ëª¨ë‘ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        # ì¢…í•© ë­í‚¹ ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', '')}
            for item in data if item.get('thumbnail_url')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta)
        backup_to_json(date, self.platform_id, data)

        # ì¥ë¥´ë³„ ë­í‚¹ ì €ì¥
        for genre_key, rankings in self.genre_results.items():
            if genre_key == '':
                continue
            genre_name = self.GENRE_RANKINGS[genre_key]['name']
            save_rankings(date, self.platform_id, rankings, sub_category=genre_key)
            genre_meta = [
                {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
                 'url': item.get('url', '')}
                for item in rankings if item.get('thumbnail_url')
            ]
            if genre_meta:
                save_works_metadata(self.platform_id, genre_meta)
            self.logger.info(f"   ğŸ’¾ [{genre_name}]: {len(rankings)}ê°œ ì €ì¥")


if __name__ == "__main__":
    import asyncio
    from playwright.async_api import async_playwright

    async def test():
        print("=" * 60)
        print("ë¼ì¸ë§ê°€ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)

            try:
                agent = LinemangaAgent()
                result = await agent.execute(browser)

                print(f"\nâœ… Success: {result.success}")
                print(f"âœ… Count: {result.count}")

                if result.success and result.data:
                    print(f"\nìƒ˜í”Œ (1~5ìœ„):")
                    for item in result.data[:5]:
                        print(f"  {item['rank']}ìœ„: {item['title']}")
                        print(f"    ì¥ë¥´: {item['genre']}")
                        print(f"    URL: {item['url']}")

                    # ì¥ë¥´ë³„ ê²°ê³¼ ìš”ì•½
                    print(f"\nì¥ë¥´ë³„ ê²°ê³¼:")
                    for gkey, rankings in agent.genre_results.items():
                        label = agent.GENRE_RANKINGS[gkey]['name']
                        print(f"  [{label}]: {len(rankings)}ê°œ")
                else:
                    print(f"\nâŒ Error: {result.error}")

            finally:
                await browser.close()

        print("\n" + "=" * 60)

    asyncio.run(test())
