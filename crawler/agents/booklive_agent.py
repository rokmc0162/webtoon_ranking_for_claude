"""
ë¶ë¼ì´ë¸Œ (BookLive) í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸

íŠ¹ì§•:
- SSR ë°©ì‹ (ì„œë²„ ë Œë”ë§, ê°€ì¥ ë°ì´í„° í’ë¶€)
- 100ê°œ/í˜ì´ì§€, í˜ì´ì§€ë„¤ì´ì…˜ ìˆìŒ
- IP ì œí•œ ì—†ìŒ
- li.item.clearfix > div.left > div.picture > a > img êµ¬ì¡°
"""

import re
from typing import List, Dict, Any
from playwright.async_api import Browser

from crawler.agents.base_agent import CrawlerAgent


class BookliveAgent(CrawlerAgent):
    """ë¶ë¼ì´ë¸Œ ì¼ê°„/ì¢…í•© ë­í‚¹ í¬ë¡¤ëŸ¬ ì—ì´ì „íŠ¸"""

    GENRE_RANKINGS = {
        '': {'name': 'ì¢…í•©', 'path': '/ranking/day'},
        'å°‘å¹´ãƒãƒ³ã‚¬': {'name': 'ì†Œë…„ë§Œí™”', 'path': '/ranking/day/category_id/C/genre_id/6'},
        'é’å¹´ãƒãƒ³ã‚¬': {'name': 'ì²­ë…„ë§Œí™”', 'path': '/ranking/day/category_id/C/genre_id/5'},
        'å°‘å¥³ãƒãƒ³ã‚¬': {'name': 'ì†Œë…€ë§Œí™”', 'path': '/ranking/day/category_id/CF/genre_id/1'},
        'å¥³æ€§ãƒãƒ³ã‚¬': {'name': 'ì—¬ì„±ë§Œí™”', 'path': '/ranking/day/category_id/CF/genre_id/2'},
        'BL': {'name': 'BL', 'path': '/ranking/day/category_id/BL/genre_id/3'},
        'TL': {'name': 'TL', 'path': '/ranking/day/category_id/TL/genre_id/7'},
        'ãƒ©ãƒãƒ™': {'name': 'ë¼ë…¸ë²¨', 'path': '/ranking/day/category_id/L/genre_id/14'},
    }

    def __init__(self):
        super().__init__(
            platform_id='booklive',
            platform_name='ë¶ë¼ì´ë¸Œ (BookLive)',
            url='https://booklive.jp/ranking/day'
        )
        self.genre_results = {}

    async def crawl(self, browser: Browser) -> List[Dict[str, Any]]:
        """ë¶ë¼ì´ë¸Œ ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ í¬ë¡¤ë§"""
        page = await browser.new_page()
        all_rankings = []

        try:
            for genre_key, genre_info in self.GENRE_RANKINGS.items():
                label = genre_info['name']
                path = genre_info['path']
                url = f'https://booklive.jp{path}'

                try:
                    self.logger.info(f"ğŸ“± ë¶ë¼ì´ë¸Œ [{label}] í¬ë¡¤ë§ ì¤‘... â†’ {url}")

                    await page.goto(url, wait_until='domcontentloaded', timeout=20000)
                    await page.wait_for_timeout(3000)

                    # DOM ê¸°ë°˜ íŒŒì‹± (ì¸ë„¤ì¼ í¬í•¨)
                    rankings = await self._parse_dom_rankings(page, genre_key)

                    # í´ë°±: í…ìŠ¤íŠ¸ ê¸°ë°˜
                    if len(rankings) < 5:
                        self.logger.info("   DOM íŒŒì‹± ë¶€ì¡±, í…ìŠ¤íŠ¸ í´ë°±...")
                        body_text = await page.inner_text('body')
                        rankings = self._parse_text_rankings(body_text, genre_key)

                    self.genre_results[genre_key] = rankings
                    self.logger.info(f"   âœ… [{label}]: {len(rankings)}ê°œ ì‘í’ˆ")

                    if genre_key == '':
                        all_rankings = rankings
                except Exception as e:
                    self.logger.warning(f"   âš ï¸ [{label}] í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                    self.genre_results[genre_key] = []

            return all_rankings

        finally:
            await page.close()

    async def _parse_dom_rankings(self, page, genre_key: str) -> List[Dict[str, Any]]:
        """DOMì—ì„œ ë­í‚¹ ì•„ì´í…œ + ì¸ë„¤ì¼ ì¶”ì¶œ"""
        items = await page.evaluate("""() => {
            const results = [];
            // booklive: ul.search_item_list > li.item > div.left > div.picture > a > img
            // img id: search_image_1, search_image_2, ...
            // img altì— íƒ€ì´í‹€ í¬í•¨
            const listItems = document.querySelectorAll('ul.search_item_list li.item, li.item.clearfix');
            let rank = 0;

            for (const li of listItems) {
                // ì¸ë„¤ì¼ (div.picture ì•ˆì˜ img)
                const img = li.querySelector('div.picture img, img[id^="search_image"]');
                if (!img) continue;

                const src = img.getAttribute('src') || '';
                if (!src || src.includes('blank') || src.includes('spacer')) continue;

                // íƒ€ì´í‹€: img alt ë˜ëŠ” í…ìŠ¤íŠ¸ ìš”ì†Œ
                let title = img.getAttribute('alt') || '';
                if (!title || title.length < 2) {
                    const titleEl = li.querySelector('a.product_title, p.title a, h3 a, a[href*="/product/"]');
                    if (titleEl) title = titleEl.textContent.trim();
                }
                if (!title || title.length < 2) continue;

                // URL
                const linkEl = li.querySelector('a[href*="/product/"]');
                const href = linkEl ? linkEl.getAttribute('href') : '';
                const fullUrl = href ? (href.startsWith('http') ? href : 'https://booklive.jp' + href) : '';

                const thumbUrl = src.startsWith('http') ? src : (src.startsWith('//') ? 'https:' + src : '');

                rank++;
                if (rank <= 100) {
                    results.push({
                        rank: rank,
                        title: title,
                        url: fullUrl,
                        thumbnail_url: thumbUrl,
                    });
                }
            }
            return results;
        }""")

        return [
            {
                'rank': item['rank'],
                'title': item['title'],
                'genre': genre_key,
                'url': item.get('url', ''),
                'thumbnail_url': item.get('thumbnail_url', ''),
            }
            for item in items[:100]
        ]

    def _parse_text_rankings(self, body_text: str, genre_key: str) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ ë­í‚¹ ì•„ì´í…œ ì¶”ì¶œ (Nä½ íŒ¨í„´) - í´ë°±"""
        lines = [l.strip() for l in body_text.split('\n') if l.strip()]
        rankings = []

        i = 0
        while i < len(lines) and len(rankings) < 100:
            line = lines[i]
            rank_match = re.match(r'^(\d+)ä½$', line)
            if rank_match:
                rank = int(rank_match.group(1))
                if i + 1 < len(lines):
                    title = lines[i + 1].strip()
                    if len(title) >= 2 and not title.endswith('ä½'):
                        genre = genre_key
                        if not genre:
                            for j in range(i + 2, min(i + 6, len(lines))):
                                g = lines[j].strip()
                                if g in ['å°‘å¹´ãƒãƒ³ã‚¬', 'é’å¹´ãƒãƒ³ã‚¬', 'å°‘å¥³ãƒãƒ³ã‚¬',
                                         'å¥³æ€§ãƒãƒ³ã‚¬', 'BL', 'TL', 'ãƒ©ãƒãƒ™']:
                                    genre = g
                                    break

                        rankings.append({
                            'rank': rank,
                            'title': title,
                            'genre': genre,
                            'url': 'https://booklive.jp/ranking/day',
                            'thumbnail_url': '',
                        })
            i += 1

        return rankings

    async def save(self, date: str, data: List[Dict[str, Any]]):
        """ì¢…í•© + ì¥ë¥´ë³„ ë­í‚¹ ëª¨ë‘ ì €ì¥"""
        from crawler.db import save_rankings, backup_to_json, save_works_metadata

        save_rankings(date, self.platform_id, data, sub_category='')
        works_meta = [
            {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
             'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
            for item in data if item.get('thumbnail_url')
        ]
        if works_meta:
            save_works_metadata(self.platform_id, works_meta, date=date, sub_category='')
        backup_to_json(date, self.platform_id, data)

        for genre_key, rankings in self.genre_results.items():
            if genre_key == '':
                continue
            genre_name = self.GENRE_RANKINGS[genre_key]['name']
            save_rankings(date, self.platform_id, rankings, sub_category=genre_key)
            genre_meta = [
                {'title': item['title'], 'thumbnail_url': item.get('thumbnail_url', ''),
                 'url': item.get('url', ''), 'genre': item.get('genre', ''), 'rank': item.get('rank')}
                for item in rankings if item.get('thumbnail_url')
            ]
            if genre_meta:
                save_works_metadata(self.platform_id, genre_meta, date=date, sub_category=genre_key)
            self.logger.info(f"   ğŸ’¾ [{genre_name}]: {len(rankings)}ê°œ ì €ì¥")
