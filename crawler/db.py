"""
Supabase PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë° ì €ì¥ ë¡œì§
"""

import psycopg2
import json
import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
import sys
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from crawler.utils import get_korean_title, is_riverse_title, translate_genre

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(project_root / '.env')
DATABASE_URL = os.environ.get('SUPABASE_DB_URL', '')


def get_db_connection():
    """Supabase PostgreSQL ì—°ê²°"""
    conn = psycopg2.connect(DATABASE_URL)
    return conn


def init_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute('SELECT 1')
        conn.close()
        print(f"âœ… DB ì—°ê²° í™•ì¸ ì™„ë£Œ: Supabase PostgreSQL")
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        raise


def save_rankings(date: str, platform: str, rankings: List[Dict[str, Any]],
                   sub_category: str = ''):
    """
    ë­í‚¹ ë°ì´í„° ì €ì¥ (upsert ë°©ì‹)

    Args:
        date: ë‚ ì§œ (YYYY-MM-DD)
        platform: í”Œë«í¼ ì´ë¦„ (piccoma, linemanga, mechacomic, cmoa)
        rankings: ë­í‚¹ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        sub_category: ì„œë¸Œ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: 'ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼', 'æ‹æ„›' ë“±, ê¸°ë³¸: '' = ì¢…í•©)
    """
    if not rankings:
        print(f"âš ï¸  {platform}: ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
        return

    conn = get_db_connection()
    cursor = conn.cursor()

    saved_count = 0
    for item in rankings:
        # ì œëª© ë§¤í•‘
        title_kr = get_korean_title(item['title'])

        # ì¥ë¥´ ë²ˆì—­
        genre_kr = translate_genre(item.get('genre', ''))

        # ë¦¬ë²„ìŠ¤ ì‘í’ˆ ì—¬ë¶€
        is_riverse = is_riverse_title(item['title'])

        try:
            cursor.execute('''
                INSERT INTO rankings
                (date, platform, sub_category, rank, title, title_kr, genre, genre_kr, url, is_riverse)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (date, platform, sub_category, rank)
                DO UPDATE SET
                    title = EXCLUDED.title,
                    title_kr = EXCLUDED.title_kr,
                    genre = EXCLUDED.genre,
                    genre_kr = EXCLUDED.genre_kr,
                    url = EXCLUDED.url,
                    is_riverse = EXCLUDED.is_riverse
            ''', (
                date,
                platform,
                sub_category,
                item['rank'],
                item['title'],
                title_kr,
                item.get('genre', ''),
                genre_kr,
                item.get('url', ''),
                is_riverse
            ))
            saved_count += 1
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨ ({platform} {item['rank']}ìœ„): {e}")

    conn.commit()
    conn.close()

    print(f"ğŸ’¾ {platform}: {saved_count}ê°œ ì‘í’ˆ DB ì €ì¥")


def _upsert_unified_work(cursor, title_kr: str, title: str, author: str = '',
                          publisher: str = '', genre: str = '', genre_kr: str = '',
                          tags: str = '', description: str = '',
                          is_riverse: bool = False, thumbnail_url: str = '',
                          thumbnail_base64: str = '') -> Optional[int]:
    """
    unified_works í…Œì´ë¸” UPSERT í›„ id ë°˜í™˜.
    title_krì´ ë¹„ì–´ìˆìœ¼ë©´ None ë°˜í™˜.
    """
    if not title_kr:
        return None

    cursor.execute('''
        INSERT INTO unified_works
            (title_kr, title_canonical, author, publisher, genre, genre_kr,
             tags, description, is_riverse, thumbnail_url, thumbnail_base64)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        ON CONFLICT (title_kr) DO UPDATE SET
            title_canonical = COALESCE(NULLIF(EXCLUDED.title_canonical, ''), unified_works.title_canonical),
            author = COALESCE(NULLIF(EXCLUDED.author, ''), unified_works.author),
            publisher = COALESCE(NULLIF(EXCLUDED.publisher, ''), unified_works.publisher),
            genre = COALESCE(NULLIF(EXCLUDED.genre, ''), unified_works.genre),
            genre_kr = COALESCE(NULLIF(EXCLUDED.genre_kr, ''), unified_works.genre_kr),
            tags = CASE WHEN length(EXCLUDED.tags) > length(COALESCE(unified_works.tags, ''))
                   THEN EXCLUDED.tags ELSE unified_works.tags END,
            description = CASE WHEN length(EXCLUDED.description) > length(COALESCE(unified_works.description, ''))
                          THEN EXCLUDED.description ELSE unified_works.description END,
            is_riverse = EXCLUDED.is_riverse OR unified_works.is_riverse,
            thumbnail_url = COALESCE(NULLIF(EXCLUDED.thumbnail_url, ''), unified_works.thumbnail_url),
            thumbnail_base64 = COALESCE(NULLIF(EXCLUDED.thumbnail_base64, ''), unified_works.thumbnail_base64),
            updated_at = NOW()
        RETURNING id
    ''', (
        title_kr, title, author, publisher, genre, genre_kr,
        tags, description, is_riverse, thumbnail_url, thumbnail_base64
    ))
    row = cursor.fetchone()
    return row[0] if row else None


def save_works_metadata(platform: str, works: List[Dict[str, Any]],
                        date: str = '', sub_category: str = ''):
    """
    ì‘í’ˆ ë©”íƒ€ë°ì´í„° ì €ì¥/ê°±ì‹  (ë…ë¦½ ì‘í’ˆ DB)
    + unified_works ìë™ ì—°ê²°

    Args:
        platform: í”Œë«í¼ ì´ë¦„
        works: [{'title': str, 'thumbnail_url': str, 'url': str, 'genre': str, 'rank': int}, ...]
        date: í¬ë¡¤ë§ ë‚ ì§œ (YYYY-MM-DD) â€” first/last_seen_date ê°±ì‹ ìš©
        sub_category: ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ('' = ì¢…í•© â†’ best_rank ê°±ì‹ )
    """
    if not works:
        return

    conn = get_db_connection()
    cursor = conn.cursor()

    count = 0
    for item in works:
        title = item.get('title', '')
        thumbnail_url = item.get('thumbnail_url', '')
        url = item.get('url', '')
        genre = item.get('genre', '')
        rank = item.get('rank', None)

        if not title:
            continue

        # í•œêµ­ì–´ ì œëª©, ë¦¬ë²„ìŠ¤ ì—¬ë¶€ ê³„ì‚°
        title_kr = get_korean_title(title)
        genre_kr = translate_genre(genre) if genre else ''
        is_riverse = is_riverse_title(title)

        # unified_works UPSERT â†’ id íšë“
        unified_id = _upsert_unified_work(
            cursor, title_kr, title,
            genre=genre, genre_kr=genre_kr,
            is_riverse=is_riverse, thumbnail_url=thumbnail_url
        )

        # UPSERT: ì‹ ê·œ ì‘í’ˆì´ë©´ INSERT, ê¸°ì¡´ì´ë©´ ê°±ì‹ 
        cursor.execute('''
            INSERT INTO works (platform, title, thumbnail_url, url, genre, genre_kr,
                               title_kr, is_riverse, first_seen_date, last_seen_date,
                               best_rank, unified_work_id, updated_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s,
                    CASE WHEN %s != '' THEN %s::date ELSE NULL END,
                    CASE WHEN %s != '' THEN %s::date ELSE NULL END,
                    CASE WHEN %s = '' AND %s IS NOT NULL THEN %s ELSE NULL END,
                    %s, NOW())
            ON CONFLICT(platform, title)
            DO UPDATE SET
                thumbnail_url = CASE WHEN EXCLUDED.thumbnail_url != '' THEN EXCLUDED.thumbnail_url
                                     ELSE works.thumbnail_url END,
                url = CASE WHEN EXCLUDED.url != '' THEN EXCLUDED.url ELSE works.url END,
                genre = CASE WHEN EXCLUDED.genre != '' THEN EXCLUDED.genre ELSE works.genre END,
                genre_kr = CASE WHEN EXCLUDED.genre_kr != '' THEN EXCLUDED.genre_kr ELSE works.genre_kr END,
                title_kr = CASE WHEN EXCLUDED.title_kr != '' THEN EXCLUDED.title_kr ELSE works.title_kr END,
                is_riverse = EXCLUDED.is_riverse OR works.is_riverse,
                first_seen_date = LEAST(works.first_seen_date, EXCLUDED.first_seen_date),
                last_seen_date = GREATEST(works.last_seen_date, EXCLUDED.last_seen_date),
                best_rank = CASE
                    WHEN EXCLUDED.best_rank IS NOT NULL AND (works.best_rank IS NULL OR EXCLUDED.best_rank < works.best_rank)
                    THEN EXCLUDED.best_rank ELSE works.best_rank END,
                unified_work_id = COALESCE(EXCLUDED.unified_work_id, works.unified_work_id),
                updated_at = NOW()
        ''', (
            platform, title, thumbnail_url, url, genre, genre_kr,
            title_kr, is_riverse,
            date, date,   # first_seen_date
            date, date,   # last_seen_date
            sub_category, rank, rank,  # best_rank (only for ì¢…í•©)
            unified_id
        ))
        count += 1

    conn.commit()
    conn.close()

    if count > 0:
        print(f"ğŸ–¼ï¸  {platform}: {count}ê°œ ì‘í’ˆ ë©”íƒ€ë°ì´í„° ì €ì¥")


def get_works_thumbnails(platform: str) -> Dict[str, str]:
    """
    í”Œë«í¼ì˜ ëª¨ë“  ì‘í’ˆ ì¸ë„¤ì¼ URL ë§µ ë°˜í™˜

    Returns:
        {title: thumbnail_url} ë”•ì…”ë„ˆë¦¬
    """
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute('''
        SELECT title, thumbnail_url
        FROM works
        WHERE platform = %s AND thumbnail_url IS NOT NULL AND thumbnail_url != ''
    ''', (platform,))

    result = {row[0]: row[1] for row in cursor.fetchall()}
    conn.close()
    return result


def save_thumbnail_base64(platform: str, title: str, b64_data: str):
    """
    ì‘í’ˆ ì¸ë„¤ì¼ base64 ë°ì´í„° ì €ì¥

    Args:
        platform: í”Œë«í¼ ì´ë¦„
        title: ì‘í’ˆëª…
        b64_data: "data:image/jpeg;base64,..." í˜•ì‹ì˜ data URI
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute('''
        UPDATE works SET thumbnail_base64 = %s, updated_at = NOW()
        WHERE platform = %s AND title = %s
    ''', (b64_data, platform, title))
    conn.commit()
    conn.close()


def get_thumbnails_base64(platform: str) -> Dict[str, str]:
    """
    í”Œë«í¼ì˜ ëª¨ë“  ì‘í’ˆ ì¸ë„¤ì¼ base64 ë§µ ë°˜í™˜

    Returns:
        {title: "data:image/...;base64,..."} ë”•ì…”ë„ˆë¦¬
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute('''
        SELECT title, thumbnail_base64
        FROM works
        WHERE platform = %s AND thumbnail_base64 IS NOT NULL AND thumbnail_base64 != ''
    ''', (platform,))
    result = {row[0]: row[1] for row in cursor.fetchall()}
    conn.close()
    return result


def get_works_without_base64(platform: str) -> List[Dict[str, str]]:
    """
    base64ê°€ ì—†ì§€ë§Œ thumbnail_urlì´ ìˆëŠ” ì‘í’ˆ ëª©ë¡ ë°˜í™˜

    Returns:
        [{'title': str, 'thumbnail_url': str}, ...]
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute('''
        SELECT title, thumbnail_url
        FROM works
        WHERE platform = %s
          AND thumbnail_url IS NOT NULL AND thumbnail_url != ''
          AND (thumbnail_base64 IS NULL OR thumbnail_base64 = '')
    ''', (platform,))
    result = [{'title': row[0], 'thumbnail_url': row[1]} for row in cursor.fetchall()]
    conn.close()
    return result


def save_work_detail(platform: str, title: str, detail: Dict[str, Any]):
    """
    ì‘í’ˆ ìƒì„¸ ë©”íƒ€ë°ì´í„° ì €ì¥ (ìƒì„¸ í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘)
    COALESCE(NULLIF(...), existing) íŒ¨í„´ìœ¼ë¡œ ê¸°ì¡´ ë°ì´í„° ë³´í˜¸
    + unified_worksì—ë„ ìƒì„¸ ì •ë³´ ë°˜ì˜

    Args:
        platform: í”Œë«í¼ ì´ë¦„
        title: ì‘í’ˆ ì œëª© (ì¼ë³¸ì–´)
        detail: {author, publisher, label, tags, description, hearts, favorites, rating, review_count}
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute('''
        UPDATE works SET
            author = COALESCE(NULLIF(%s, ''), author),
            publisher = COALESCE(NULLIF(%s, ''), publisher),
            label = COALESCE(NULLIF(%s, ''), label),
            tags = COALESCE(NULLIF(%s, ''), tags),
            description = COALESCE(NULLIF(%s, ''), description),
            hearts = COALESCE(%s, hearts),
            favorites = COALESCE(%s, favorites),
            rating = COALESCE(%s, rating),
            review_count = COALESCE(%s, review_count),
            detail_scraped_at = NOW(),
            updated_at = NOW()
        WHERE platform = %s AND title = %s
    ''', (
        detail.get('author', ''),
        detail.get('publisher', ''),
        detail.get('label', ''),
        detail.get('tags', ''),
        detail.get('description', ''),
        detail.get('hearts'),
        detail.get('favorites'),
        detail.get('rating'),
        detail.get('review_count'),
        platform, title
    ))
    updated = cursor.rowcount

    # unified_worksì—ë„ ìƒì„¸ ì •ë³´ ë°˜ì˜
    title_kr = get_korean_title(title)
    if title_kr:
        _upsert_unified_work(
            cursor, title_kr, title,
            author=detail.get('author', ''),
            publisher=detail.get('publisher', ''),
            tags=detail.get('tags', ''),
            description=detail.get('description', ''),
        )

    conn.commit()
    conn.close()
    return updated > 0


def save_reviews(platform: str, work_title: str, reviews: List[Dict[str, Any]]) -> int:
    """
    ë¦¬ë·°/ì½”ë©˜íŠ¸ ë²Œí¬ ì €ì¥ (ON CONFLICT DO NOTHINGìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€)

    Args:
        platform: í”Œë«í¼ ì´ë¦„
        work_title: ì‘í’ˆ ì œëª© (ì¼ë³¸ì–´)
        reviews: [{reviewer_name, reviewer_info, body, rating, likes_count, is_spoiler, reviewed_at}]

    Returns:
        ì €ì¥ëœ ë¦¬ë·° ìˆ˜
    """
    if not reviews:
        return 0

    conn = get_db_connection()
    cursor = conn.cursor()
    count = 0
    for r in reviews:
        try:
            cursor.execute('''
                INSERT INTO reviews
                (platform, work_title, reviewer_name, reviewer_info, body,
                 rating, likes_count, is_spoiler, reviewed_at, collected_at)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
                ON CONFLICT (platform, work_title, reviewer_name, reviewed_at)
                DO NOTHING
            ''', (
                platform, work_title,
                r.get('reviewer_name', ''),
                r.get('reviewer_info', ''),
                r.get('body', ''),
                r.get('rating'),
                r.get('likes_count', 0),
                r.get('is_spoiler', False),
                r.get('reviewed_at')
            ))
            if cursor.rowcount > 0:
                count += 1
        except Exception as e:
            print(f"âš ï¸  ë¦¬ë·° ì €ì¥ ì‹¤íŒ¨: {e}")
    conn.commit()
    conn.close()
    return count


def get_works_needing_detail(max_count: int = 50, riverse_only: bool = False) -> List[Dict[str, str]]:
    """
    ìƒì„¸ ë©”íƒ€ë°ì´í„°ê°€ í•„ìš”í•œ ì‘í’ˆ ëª©ë¡ ì¡°íšŒ
    - detail_scraped_atì´ NULLì´ê±°ë‚˜ 7ì¼ ì´ìƒ ì§€ë‚œ ì‘í’ˆ
    - ìµœê·¼ ë­í‚¹ ë“±ì¥ ìˆœìœ¼ë¡œ ìš°ì„ 

    Args:
        max_count: ìµœëŒ€ ì‘í’ˆ ìˆ˜
        riverse_only: Trueì´ë©´ ë¦¬ë²„ìŠ¤ ì‘í’ˆë§Œ (detail_scraped_at ì¡°ê±´ ë¬´ì‹œ, ê°•ì œ ì¬ìˆ˜ì§‘)

    Returns:
        [{platform, title, url}, ...]
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    if riverse_only:
        # ë¦¬ë²„ìŠ¤ ì‘í’ˆì€ ê¸°ì¡´ ìˆ˜ì§‘ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ ì „ë¶€ ì¬ìˆ˜ì§‘
        cursor.execute('''
            SELECT platform, title, url
            FROM works
            WHERE url IS NOT NULL AND url != ''
              AND is_riverse = TRUE
              AND platform != 'asura'
            ORDER BY last_seen_date DESC NULLS LAST
            LIMIT %s
        ''', (max_count,))
    else:
        cursor.execute('''
            SELECT platform, title, url
            FROM works
            WHERE url IS NOT NULL AND url != ''
              AND (detail_scraped_at IS NULL
                   OR detail_scraped_at < NOW() - INTERVAL '7 days')
            ORDER BY last_seen_date DESC NULLS LAST,
                     detail_scraped_at ASC NULLS FIRST
            LIMIT %s
        ''', (max_count,))
    result = [{'platform': r[0], 'title': r[1], 'url': r[2]} for r in cursor.fetchall()]
    conn.close()
    return result


def get_works_for_review(max_count: int = 100, riverse_only: bool = False) -> List[Dict[str, str]]:
    """
    ë¦¬ë·° ìˆ˜ì§‘ ëŒ€ìƒ ì‘í’ˆ ëª©ë¡ (ìµœê·¼ 7ì¼ ë­í‚¹ ë“±ì¥, í”½ì½”ë§ˆ ì œì™¸)
    í”Œë«í¼ë³„ ê· ë“± ë¶„ë°°: max_countë¥¼ í”Œë«í¼ ìˆ˜ë¡œ ë‚˜ëˆ ì„œ ê° í”Œë«í¼ì—ì„œ ê³ ë¥´ê²Œ ê°€ì ¸ì˜´

    Args:
        max_count: ìµœëŒ€ ì‘í’ˆ ìˆ˜ (0 = ë¬´ì œí•œ)
        riverse_only: Trueì´ë©´ ë¦¬ë²„ìŠ¤ ì‘í’ˆë§Œ (7ì¼ ì œí•œ í•´ì œ)

    Returns:
        [{platform, title, url}, ...]
    """
    conn = get_db_connection()
    cursor = conn.cursor()

    if riverse_only:
        # ë¦¬ë²„ìŠ¤ ì‘í’ˆ ì „ì²´ (ë‚ ì§œ ì œí•œ ì—†ì´, í”½ì½”ë§ˆ/ì•„ìˆ˜ë¼ ì œì™¸)
        cursor.execute('''
            SELECT DISTINCT w.platform, w.title, w.url
            FROM works w
            WHERE w.is_riverse = TRUE
              AND w.platform NOT IN ('piccoma', 'asura')
              AND w.url IS NOT NULL AND w.url != ''
            ORDER BY w.platform, w.title
        ''')
    elif max_count <= 0 or max_count >= 10000:
        # ë¬´ì œí•œ: ì „ì²´ ê°€ì ¸ì˜¤ê¸°
        cursor.execute('''
            SELECT DISTINCT w.platform, w.title, w.url
            FROM works w
            WHERE w.platform != 'piccoma'
              AND w.url IS NOT NULL AND w.url != ''
              AND w.last_seen_date >= (CURRENT_DATE - INTERVAL '7 days')::date
            ORDER BY w.platform, w.title
        ''')
    else:
        # í”Œë«í¼ë³„ ê· ë“± ë¶„ë°° (WINDOW í•¨ìˆ˜ ì‚¬ìš©)
        cursor.execute('''
            SELECT platform, title, url FROM (
                SELECT w.platform, w.title, w.url,
                       ROW_NUMBER() OVER (PARTITION BY w.platform ORDER BY w.title) as rn
                FROM works w
                WHERE w.platform != 'piccoma'
                  AND w.url IS NOT NULL AND w.url != ''
                  AND w.last_seen_date >= (CURRENT_DATE - INTERVAL '7 days')::date
            ) sub
            WHERE rn <= %s
            ORDER BY platform, title
        ''', (max_count,))

    result = [{'platform': r[0], 'title': r[1], 'url': r[2]} for r in cursor.fetchall()]
    conn.close()
    return result


def get_works_genres(platform: str) -> Dict[str, str]:
    """
    í”Œë«í¼ì˜ ëª¨ë“  ì‘í’ˆ ì¥ë¥´ ìºì‹œ ë§µ ë°˜í™˜

    Returns:
        {title: genre} ë”•ì…”ë„ˆë¦¬
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute('''
        SELECT title, genre
        FROM works
        WHERE platform = %s AND genre IS NOT NULL AND genre != ''
    ''', (platform,))
    result = {row[0]: row[1] for row in cursor.fetchall()}
    conn.close()
    return result


def save_work_genre(platform: str, title: str, genre: str):
    """ì‘í’ˆ ì¥ë¥´ë¥¼ works í…Œì´ë¸”ì— ìºì‹œ ì €ì¥"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute('''
        UPDATE works SET genre = %s, updated_at = NOW()
        WHERE platform = %s AND title = %s
    ''', (genre, platform, title))
    if cursor.rowcount == 0:
        # worksì— ì•„ì§ ì—†ìœ¼ë©´ insert
        cursor.execute('''
            INSERT INTO works (platform, title, genre, updated_at)
            VALUES (%s, %s, %s, NOW())
            ON CONFLICT (platform, title) DO NOTHING
        ''', (platform, title, genre))
    conn.commit()
    conn.close()


def update_rankings_genre(platform: str, title: str, genre: str, genre_kr: str):
    """rankings í…Œì´ë¸”ì—ì„œ ì¥ë¥´ê°€ ë¹„ì–´ìˆëŠ” í•´ë‹¹ ì‘í’ˆ ë ˆì½”ë“œë¥¼ ëª¨ë‘ ì—…ë°ì´íŠ¸"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute('''
        UPDATE rankings SET genre = %s, genre_kr = %s
        WHERE platform = %s AND title = %s AND (genre IS NULL OR genre = '')
    ''', (genre, genre_kr, platform, title))
    conn.commit()
    conn.close()


def backup_to_json(date: str, platform: str, rankings: List[Dict[str, Any]]):
    """
    JSON ë°±ì—… ì €ì¥ (DB ì¥ì•  ëŒ€ë¹„)

    Args:
        date: ë‚ ì§œ (YYYY-MM-DD)
        platform: í”Œë«í¼ ì´ë¦„
        rankings: ë­í‚¹ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    backup_dir = project_root / 'data' / 'backup' / date
    backup_dir.mkdir(parents=True, exist_ok=True)

    backup_file = backup_dir / f'{platform}.json'

    with open(backup_file, 'w', encoding='utf-8') as f:
        json.dump(rankings, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“¦ {platform}: JSON ë°±ì—… ì™„ë£Œ ({backup_file})")


def get_available_dates() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ëª©ë¡ ë°˜í™˜ (ìµœì‹ ìˆœ)"""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute('''
        SELECT DISTINCT date
        FROM rankings
        ORDER BY date DESC
    ''')

    dates = [row[0] for row in cursor.fetchall()]
    conn.close()

    return dates


def get_rank_history(title: str, platform: str, days: int = 30) -> List[Dict[str, Any]]:
    """
    íŠ¹ì • ì‘í’ˆì˜ ìˆœìœ„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ

    Args:
        title: ì‘í’ˆëª… (ì¼ë³¸ì–´)
        platform: í”Œë«í¼ ì´ë¦„
        days: ì¡°íšŒ ì¼ìˆ˜ (ê¸°ë³¸ 30ì¼)

    Returns:
        [{'date': '2026-02-15', 'rank': 1}, ...]
    """
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute('''
        SELECT date, rank
        FROM rankings
        WHERE title = %s AND platform = %s
        ORDER BY date DESC
        LIMIT %s
    ''', (title, platform, days))

    history = [
        {'date': row[0], 'rank': row[1]}
        for row in cursor.fetchall()
    ]

    conn.close()

    # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ (ê·¸ë˜í”„ìš©)
    history.reverse()

    return history


def get_previous_date(date: str, platform: str) -> Optional[str]:
    """
    íŠ¹ì • ë‚ ì§œ ì´ì „ì˜ ê°€ì¥ ìµœê·¼ ë‚ ì§œ ë°˜í™˜

    Args:
        date: ê¸°ì¤€ ë‚ ì§œ (YYYY-MM-DD)
        platform: í”Œë«í¼ ì´ë¦„

    Returns:
        ì´ì „ ë‚ ì§œ (YYYY-MM-DD) ë˜ëŠ” None
    """
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute('''
        SELECT DISTINCT date
        FROM rankings
        WHERE date < %s AND platform = %s
        ORDER BY date DESC
        LIMIT 1
    ''', (date, platform))

    row = cursor.fetchone()
    conn.close()

    return row[0] if row else None


def calculate_rank_changes(date: str, platform: str) -> Dict[str, int]:
    """
    ì „ì¼ ëŒ€ë¹„ ìˆœìœ„ ë³€ë™ ê³„ì‚°

    Args:
        date: í˜„ì¬ ë‚ ì§œ
        platform: í”Œë«í¼ ì´ë¦„

    Returns:
        {ì œëª©: ë³€ë™ê°’} ë”•ì…”ë„ˆë¦¬
        - ì–‘ìˆ˜: ìˆœìœ„ ìƒìŠ¹ (ì˜ˆ: 10ìœ„ â†’ 5ìœ„ = +5)
        - ìŒìˆ˜: ìˆœìœ„ í•˜ë½
        - 999: ì‹ ê·œ ì§„ì… (NEW)
        - 0: ë³€ë™ ì—†ìŒ
    """
    prev_date = get_previous_date(date, platform)
    if not prev_date:
        return {}  # ì´ì „ ë°ì´í„° ì—†ìŒ

    conn = get_db_connection()
    cursor = conn.cursor()

    # í˜„ì¬ ë‚ ì§œ ë­í‚¹
    cursor.execute('''
        SELECT title, rank
        FROM rankings
        WHERE date = %s AND platform = %s
    ''', (date, platform))
    current = {row[0]: row[1] for row in cursor.fetchall()}

    # ì´ì „ ë‚ ì§œ ë­í‚¹
    cursor.execute('''
        SELECT title, rank
        FROM rankings
        WHERE date = %s AND platform = %s
    ''', (prev_date, platform))
    previous = {row[0]: row[1] for row in cursor.fetchall()}

    conn.close()

    # ë³€ë™ ê³„ì‚°
    changes = {}
    for title, current_rank in current.items():
        if title in previous:
            prev_rank = previous[title]
            changes[title] = prev_rank - current_rank  # ì–‘ìˆ˜ = ìƒìŠ¹
        else:
            changes[title] = 999  # ì‹ ê·œ ì§„ì…

    return changes


if __name__ == "__main__":
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    init_db()
    print("\nâœ… DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
