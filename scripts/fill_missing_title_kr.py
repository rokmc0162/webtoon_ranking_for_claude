#!/usr/bin/env python3
"""
title_kr ëˆ„ë½ ì‘í’ˆ ì¼ê´„ ë²ˆì—­ ìŠ¤í¬ë¦½íŠ¸

1. DBì—ì„œ title_krì´ ë¹„ì–´ìˆëŠ” ê³ ìœ  ì¼ë³¸ì–´ ì œëª© ìˆ˜ì§‘
2. Claude APIë¡œ ë°°ì¹˜ ë²ˆì—­ (50ê°œì”©)
3. title_mappings.json ì—…ë°ì´íŠ¸
4. DB (works + rankings) ì—…ë°ì´íŠ¸
"""

import os
import sys
import json
import time
import anthropic
import psycopg2

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from dotenv import load_dotenv
load_dotenv()
load_dotenv(os.path.join(os.path.dirname(__file__), '..', 'dashboard-next', '.env.local'), override=True)

DB_URL = os.environ['SUPABASE_DB_URL']
API_KEY = os.environ['ANTHROPIC_API_KEY']
MAPPINGS_PATH = os.path.join(os.path.dirname(__file__), '..', 'data', 'title_mappings.json')

BATCH_SIZE = 80  # Claudeì— í•œ ë²ˆì— ë³´ë‚´ëŠ” ì œëª© ìˆ˜


def get_missing_titles() -> list[str]:
    """DBì—ì„œ title_krì´ ë¹„ì–´ìˆëŠ” ê³ ìœ  ì œëª© ìˆ˜ì§‘"""
    conn = psycopg2.connect(DB_URL)
    cur = conn.cursor()

    # works í…Œì´ë¸”ì—ì„œ title_kr ëˆ„ë½ëœ ê³ ìœ  title
    cur.execute("""
        SELECT DISTINCT title FROM works
        WHERE (title_kr IS NULL OR title_kr = '')
        ORDER BY title
    """)
    titles = [row[0] for row in cur.fetchall()]
    conn.close()
    return titles


def extract_json(text: str) -> dict:
    """ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ ì¶”ì¶œ (robust)"""
    import re
    # ```json ... ``` ë˜í•‘ ì œê±°
    text = text.strip()
    if text.startswith("```"):
        text = text.split("\n", 1)[1]
        text = text.rsplit("```", 1)[0].strip()

    # ê°€ì¥ ë°”ê¹¥ { } ì°¾ê¸°
    start = text.find("{")
    if start == -1:
        return {}

    # ì¤‘ì²© { } ì¹´ìš´íŒ…ìœ¼ë¡œ ë§¤ì¹­ë˜ëŠ” } ì°¾ê¸°
    depth = 0
    for i in range(start, len(text)):
        if text[i] == '{':
            depth += 1
        elif text[i] == '}':
            depth -= 1
            if depth == 0:
                try:
                    return json.loads(text[start:i+1])
                except json.JSONDecodeError:
                    break
    return {}


def translate_batch(client: anthropic.Anthropic, titles: list[str], retry: int = 0) -> dict[str, str]:
    """Claude APIë¡œ ì¼ë³¸ì–´ ì œëª©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
    titles_text = "\n".join(f"{i+1}. {t}" for i, t in enumerate(titles))

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=8192,
        messages=[{
            "role": "user",
            "content": f"""ë‹¤ìŒ ì¼ë³¸ì–´ ë§Œí™”/ì›¹íˆ° ì œëª©ë“¤ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.

ê·œì¹™:
- í•œêµ­ ì›¹íˆ°ì´ ì¼ë³¸ì–´ë¡œ ë²ˆì—­ëœ ê²ƒì´ë©´ ì›ë˜ í•œêµ­ì–´ ì œëª©ì„ ì°¾ì•„ì„œ ì ì–´ì£¼ì„¸ìš”
- ì¼ë³¸ ì›ì‘ì´ë©´ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”
- ì˜ì–´ ì œëª©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ë„ ë©ë‹ˆë‹¤
- ê³ ìœ ëª…ì‚¬(ìºë¦­í„°ëª… ë“±)ëŠ” ìŒì—­í•˜ì„¸ìš”
- ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”: {{"ì›ë³¸ì œëª©": "í•œêµ­ì–´ì œëª©", ...}}
- ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”

ì œëª© ëª©ë¡:
{titles_text}"""
        }]
    )

    text = response.content[0].text.strip()
    result = extract_json(text)

    if not result and retry < 2:
        print(f"  âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì¬ì‹œë„ ({retry + 1}/2)...")
        time.sleep(2)
        return translate_batch(client, titles, retry + 1)

    return result


def update_db(translations: dict[str, str]):
    """DBì˜ worksì™€ rankings í…Œì´ë¸”ì— title_kr ì—…ë°ì´íŠ¸"""
    conn = psycopg2.connect(DB_URL)
    cur = conn.cursor()

    works_updated = 0
    rankings_updated = 0

    for jp_title, kr_title in translations.items():
        if not kr_title:
            continue

        # works ì—…ë°ì´íŠ¸
        cur.execute("""
            UPDATE works SET title_kr = %s
            WHERE title = %s AND (title_kr IS NULL OR title_kr = '')
        """, (kr_title, jp_title))
        works_updated += cur.rowcount

        # rankings ì—…ë°ì´íŠ¸
        cur.execute("""
            UPDATE rankings SET title_kr = %s
            WHERE title = %s AND (title_kr IS NULL OR title_kr = '')
        """, (kr_title, jp_title))
        rankings_updated += cur.rowcount

    conn.commit()
    conn.close()
    return works_updated, rankings_updated


def update_mappings(translations: dict[str, str]):
    """title_mappings.jsonì— ìƒˆ ë§¤í•‘ ì¶”ê°€"""
    with open(MAPPINGS_PATH, 'r', encoding='utf-8') as f:
        mappings = json.load(f)

    added = 0
    for jp_title, kr_title in translations.items():
        if kr_title and jp_title not in mappings:
            mappings[jp_title] = kr_title
            added += 1

    # í‚¤ ê¸°ì¤€ ì •ë ¬ í›„ ì €ì¥
    sorted_mappings = dict(sorted(mappings.items()))
    with open(MAPPINGS_PATH, 'w', encoding='utf-8') as f:
        json.dump(sorted_mappings, f, ensure_ascii=False, indent=2)

    return added, len(sorted_mappings)


def main():
    print("=" * 60)
    print("title_kr ëˆ„ë½ ì‘í’ˆ ì¼ê´„ ë²ˆì—­")
    print("=" * 60)

    # 1. ëˆ„ë½ ì œëª© ìˆ˜ì§‘
    missing = get_missing_titles()
    print(f"\nğŸ“Š title_kr ëˆ„ë½ ê³ ìœ  ì œëª©: {len(missing)}ê°œ")

    if not missing:
        print("âœ… ëˆ„ë½ ì—†ìŒ!")
        return

    # ê¸°ì¡´ ë§¤í•‘ì—ì„œ ì´ë¯¸ ìˆëŠ” ê²ƒ ë¨¼ì € ì ìš©
    with open(MAPPINGS_PATH, 'r', encoding='utf-8') as f:
        existing_mappings = json.load(f)

    already_mapped = {}
    still_missing = []
    for t in missing:
        if t in existing_mappings:
            already_mapped[t] = existing_mappings[t]
        else:
            # ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ì²´í¬
            found = False
            for k, v in existing_mappings.items():
                if k.lower() == t.lower():
                    already_mapped[t] = v
                    found = True
                    break
            if not found:
                still_missing.append(t)

    if already_mapped:
        print(f"\nğŸ”„ ê¸°ì¡´ ë§¤í•‘ìœ¼ë¡œ {len(already_mapped)}ê°œ ë³µêµ¬ ì¤‘...")
        w, r = update_db(already_mapped)
        print(f"   works: {w}í–‰, rankings: {r}í–‰ ì—…ë°ì´íŠ¸")

    print(f"\nğŸ¤– ë²ˆì—­ í•„ìš”: {len(still_missing)}ê°œ")

    if not still_missing:
        print("âœ… ëª¨ë“  ì œëª© ë³µêµ¬ ì™„ë£Œ!")
        return

    # 2. ë°°ì¹˜ ë²ˆì—­
    client = anthropic.Anthropic(api_key=API_KEY)
    all_translations = {}

    for i in range(0, len(still_missing), BATCH_SIZE):
        batch = still_missing[i:i + BATCH_SIZE]
        batch_num = i // BATCH_SIZE + 1
        total_batches = (len(still_missing) + BATCH_SIZE - 1) // BATCH_SIZE
        print(f"\nğŸ“ ë°°ì¹˜ {batch_num}/{total_batches} ({len(batch)}ê°œ ë²ˆì—­ ì¤‘)...")

        translations = translate_batch(client, batch)
        all_translations.update(translations)
        print(f"   âœ… {len(translations)}ê°œ ë²ˆì—­ ì™„ë£Œ")

        if i + BATCH_SIZE < len(still_missing):
            time.sleep(1)  # rate limit ëŒ€ë¹„

    # 3. DB ì—…ë°ì´íŠ¸
    print(f"\nğŸ’¾ DB ì—…ë°ì´íŠ¸ ì¤‘...")
    w, r = update_db(all_translations)
    print(f"   works: {w}í–‰, rankings: {r}í–‰ ì—…ë°ì´íŠ¸")

    # 4. title_mappings.json ì—…ë°ì´íŠ¸
    added, total = update_mappings(all_translations)
    print(f"\nğŸ“ title_mappings.json: {added}ê°œ ì¶”ê°€ (ì´ {total}ê°œ)")

    # 5. ê²°ê³¼ ìš”ì•½
    print(f"\n{'=' * 60}")
    print(f"âœ… ì™„ë£Œ!")
    print(f"   ê¸°ì¡´ ë§¤í•‘ ë³µêµ¬: {len(already_mapped)}ê°œ")
    print(f"   ì‹ ê·œ ë²ˆì—­: {len(all_translations)}ê°œ")
    print(f"   ì´ ì²˜ë¦¬: {len(already_mapped) + len(all_translations)}ê°œ")


if __name__ == "__main__":
    main()
