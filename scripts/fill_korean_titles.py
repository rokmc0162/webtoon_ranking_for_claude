"""
í•œêµ­ì–´ ì œëª© ë¹ˆì¹¸ ì±„ìš°ê¸° ìŠ¤í¬ë¦½íŠ¸

rankings í…Œì´ë¸”ì—ì„œ title_krì´ ë¹„ì–´ìˆëŠ” ì‘í’ˆì„ ì°¾ì•„ì„œ:
1. ê°™ì€ ì‘í’ˆì´ ë‹¤ë¥¸ í–‰(ë‚ ì§œ/í”Œë«í¼)ì—ì„œ title_krì„ ê°€ì§€ê³  ìˆìœ¼ë©´ ë³µì‚¬
2. title_mappings.json + riverse_titles.jsonì—ì„œ ë§¤í•‘ ì‹œë„
3. ë§¤í•‘ ì•ˆ ëœ ì‘í’ˆ ëª©ë¡ì„ ì¶œë ¥í•˜ì—¬ ìˆ˜ë™ í™•ì¸ ê°€ëŠ¥

ì‚¬ìš©ë²•:
    python3 scripts/fill_korean_titles.py              # í˜„í™© í™•ì¸
    python3 scripts/fill_korean_titles.py --update      # DB ì—…ë°ì´íŠ¸
    python3 scripts/fill_korean_titles.py --missing      # ë§¤í•‘ ì•ˆ ëœ ëª©ë¡ ì¶œë ¥
"""

import sys
import os
import json
import argparse
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv(project_root / '.env')

import psycopg2

DATABASE_URL = os.environ.get('SUPABASE_DB_URL', '')


def get_db_connection():
    return psycopg2.connect(DATABASE_URL)


def load_mappings():
    """ëª¨ë“  ë§¤í•‘ íŒŒì¼ ë¡œë“œ"""
    mappings = {}

    # riverse_titles.json
    try:
        with open(project_root / 'data' / 'riverse_titles.json', 'r', encoding='utf-8') as f:
            riverse = json.load(f)
            mappings.update(riverse)
            print(f"âœ… ë¦¬ë²„ìŠ¤ ì‘í’ˆ ë§¤í•‘: {len(riverse)}ê°œ")
    except FileNotFoundError:
        print("âš ï¸  riverse_titles.json ì—†ìŒ")

    # title_mappings.json
    try:
        with open(project_root / 'data' / 'title_mappings.json', 'r', encoding='utf-8') as f:
            title_maps = json.load(f)
            mappings.update(title_maps)
            print(f"âœ… ì œëª© ë§¤í•‘: {len(title_maps)}ê°œ")
    except FileNotFoundError:
        print("âš ï¸  title_mappings.json ì—†ìŒ")

    print(f"ğŸ“š ì´ ë§¤í•‘: {len(mappings)}ê°œ")
    return mappings


def find_korean_title(jp_title, mappings):
    """ì¼ë³¸ì–´ ì œëª©ì—ì„œ í•œêµ­ì–´ ì œëª© ì°¾ê¸°"""
    if not jp_title:
        return ""

    # 1. ì •í™•í•œ ë§¤ì¹­
    if jp_title in mappings:
        return mappings[jp_title]

    # 2. ëŒ€ê´„í˜¸ ì œê±° í›„ ë§¤ì¹­
    cleaned = jp_title
    for bracket in ['ã€', 'ã€‘', '[', ']', '(', ')', 'ï¼ˆ', 'ï¼‰']:
        cleaned = cleaned.replace(bracket, '')
    cleaned = cleaned.strip()

    if cleaned != jp_title and cleaned in mappings:
        return mappings[cleaned]

    # 3. ë¶€ë¶„ ë§¤ì¹­ (4ê¸€ì ì´ìƒ)
    if len(jp_title) >= 4:
        for jp, kr in mappings.items():
            if len(jp) >= 4 and jp in jp_title:
                return kr

    return ""


def fill_from_existing_db():
    """
    DB ë‚´ì—ì„œ ê°™ì€ titleì´ ë‹¤ë¥¸ í–‰ì—ì„œ title_krì„ ê°€ì§€ê³  ìˆìœ¼ë©´ ë³µì‚¬
    (ë‹¤ë¥¸ ë‚ ì§œ, ë‹¤ë¥¸ í”Œë«í¼ì—ì„œ ì´ë¯¸ ë§¤í•‘ëœ ê²½ìš°)
    """
    conn = get_db_connection()
    cursor = conn.cursor()

    # 1. ê°™ì€ titleì´ ë‹¤ë¥¸ í–‰ì—ì„œ title_krì„ ê°€ì§€ê³  ìˆëŠ” ê²½ìš°
    cursor.execute("""
        UPDATE rankings r
        SET title_kr = sub.title_kr
        FROM (
            SELECT DISTINCT ON (title) title, title_kr
            FROM rankings
            WHERE title_kr IS NOT NULL AND title_kr != ''
            ORDER BY title, date DESC
        ) sub
        WHERE r.title = sub.title
          AND (r.title_kr IS NULL OR r.title_kr = '')
    """)
    cross_date_count = cursor.rowcount

    conn.commit()
    conn.close()
    return cross_date_count


def get_empty_title_kr_rankings():
    """title_krì´ ë¹„ì–´ìˆëŠ” ë­í‚¹ ì‘í’ˆ ì¡°íšŒ (ìµœì‹  ë‚ ì§œ, ì¢…í•©)"""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        SELECT DISTINCT r.platform, r.title, MIN(r.rank) as min_rank
        FROM rankings r
        WHERE r.date = (SELECT MAX(date) FROM rankings)
          AND COALESCE(r.sub_category, '') = ''
          AND (r.title_kr IS NULL OR r.title_kr = '')
        GROUP BY r.platform, r.title
        ORDER BY r.platform, min_rank
    """)

    results = cursor.fetchall()
    conn.close()
    return results


def update_title_kr_in_db(updates):
    """DBì— í•œêµ­ì–´ ì œëª© ì—…ë°ì´íŠ¸"""
    if not updates:
        print("ì—…ë°ì´íŠ¸í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    conn = get_db_connection()
    cursor = conn.cursor()

    updated = 0
    for jp_title, kr_title in updates:
        try:
            cursor.execute("""
                UPDATE rankings
                SET title_kr = %s
                WHERE title = %s AND (title_kr IS NULL OR title_kr = '')
            """, (kr_title, jp_title))
            rows = cursor.rowcount

            if rows > 0:
                updated += 1
        except Exception as e:
            print(f"  âŒ {jp_title}: {e}")

    conn.commit()
    conn.close()
    return updated


def main():
    parser = argparse.ArgumentParser(description='í•œêµ­ì–´ ì œëª© ë¹ˆì¹¸ ì±„ìš°ê¸°')
    parser.add_argument('--update', action='store_true', help='DBì— ë§¤í•‘ëœ ì œëª© ë°˜ì˜')
    parser.add_argument('--missing', action='store_true', help='ë§¤í•‘ ì•ˆ ëœ ì‘í’ˆ ëª©ë¡ ì¶œë ¥')
    args = parser.parse_args()

    print("=" * 60)
    print("í•œêµ­ì–´ ì œëª© ë¹ˆì¹¸ ì±„ìš°ê¸°")
    print("=" * 60)

    # Step 1: DB ë‚´ í¬ë¡œìŠ¤ ì°¸ì¡°ë¡œ ì±„ìš°ê¸°
    print("\nğŸ”„ Step 1: DB ë‚´ í¬ë¡œìŠ¤ ì°¸ì¡°ë¡œ ì±„ìš°ê¸°...")
    cross_count = fill_from_existing_db()
    print(f"   âœ… DB ë‚´ í¬ë¡œìŠ¤ ì°¸ì¡°ë¡œ {cross_count}í–‰ ì—…ë°ì´íŠ¸")

    # Step 2: ë§¤í•‘ íŒŒì¼ì—ì„œ ì°¾ê¸°
    print("\nğŸ”„ Step 2: ë§¤í•‘ íŒŒì¼ì—ì„œ ì°¾ê¸°...")
    mappings = load_mappings()

    # ë¹„ì–´ìˆëŠ” ì‘í’ˆ ì¡°íšŒ
    empty_titles = get_empty_title_kr_rankings()
    print(f"\nğŸ“Š ìµœì‹  ë­í‚¹ì—ì„œ ì•„ì§ title_kr ë¹„ì–´ìˆëŠ” ì‘í’ˆ: {len(empty_titles)}ê°œ")

    if not empty_titles:
        print("âœ… ëª¨ë“  ì‘í’ˆì— í•œêµ­ì–´ ì œëª©ì´ ìˆìŠµë‹ˆë‹¤!")
        return

    # ë§¤í•‘ ì‹œë„
    can_map = []
    cannot_map = []

    seen_titles = set()
    for platform, title, rank in empty_titles:
        if title in seen_titles:
            continue
        seen_titles.add(title)

        kr = find_korean_title(title, mappings)
        if kr:
            can_map.append((title, kr))
        else:
            cannot_map.append((platform, title, rank))

    print(f"\nâœ… ë§¤í•‘ ê°€ëŠ¥: {len(can_map)}ê°œ")
    print(f"âŒ ë§¤í•‘ ë¶ˆê°€ (ì¼ë³¸ ì˜¤ë¦¬ì§€ë„): {len(cannot_map)}ê°œ")

    # ë§¤í•‘ ê°€ëŠ¥ ëª©ë¡ ì¶œë ¥
    if can_map:
        print(f"\n--- ë§¤í•‘ ê°€ëŠ¥ ì‘í’ˆ (ìƒìœ„ 20ê°œ) ---")
        for jp, kr in can_map[:20]:
            print(f"  {jp} â†’ {kr}")
        if len(can_map) > 20:
            print(f"  ... ì™¸ {len(can_map) - 20}ê°œ")

    # DB ì—…ë°ì´íŠ¸
    if args.update and can_map:
        print(f"\nğŸ”„ ë§¤í•‘ íŒŒì¼ ê¸°ë°˜ DB ì—…ë°ì´íŠ¸ ì¤‘...")
        updated = update_title_kr_in_db(can_map)
        print(f"ğŸ’¾ {updated}ê°œ ì‘í’ˆì˜ í•œêµ­ì–´ ì œëª© ì—…ë°ì´íŠ¸ ì™„ë£Œ")

    # ë§¤í•‘ ë¶ˆê°€ ëª©ë¡ ì¶œë ¥
    if args.missing and cannot_map:
        print(f"\n--- ë§¤í•‘ ë¶ˆê°€ ì‘í’ˆ (í”Œë«í¼ë³„) ---")
        by_platform = {}
        for platform, title, rank in cannot_map:
            if platform not in by_platform:
                by_platform[platform] = []
            by_platform[platform].append((title, rank))

        for platform, titles in sorted(by_platform.items()):
            print(f"\n  [{platform}] ({len(titles)}ê°œ)")
            for title, rank in titles[:20]:
                print(f"    {rank:3d}ìœ„: {title}")
            if len(titles) > 20:
                print(f"    ... ì™¸ {len(titles) - 20}ê°œ")

    # ìš”ì•½
    total_empty = len(empty_titles)
    total_unique = len(seen_titles)
    filled = len(can_map)
    remaining = len(cannot_map)

    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š ìš”ì•½:")
    print(f"   ë¹„ì–´ìˆëŠ” ì‘í’ˆ (ì¢…í•© ë­í‚¹): {total_empty}ê°œ ({total_unique}ê°œ ê³ ìœ )")
    print(f"   ë§¤í•‘ ê°€ëŠ¥: {filled}ê°œ")
    print(f"   ë§¤í•‘ ë¶ˆê°€ (ì¼ë³¸ ì˜¤ë¦¬ì§€ë„): {remaining}ê°œ")
    if not args.update and can_map:
        print(f"\n   ğŸ’¡ --update ì˜µì…˜ìœ¼ë¡œ ë§¤í•‘ ê°€ëŠ¥í•œ {filled}ê°œë¥¼ DBì— ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    print("=" * 60)


if __name__ == "__main__":
    main()
